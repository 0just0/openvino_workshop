{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setupvars.sh] OpenVINO environment initialized\r\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "First step of this workshop is initializing OpenVINO environment in this Jupyter notebook. \n",
    "The OpenVINO 2020 R1 package have been installed to `intel/openvino/` already.\n",
    "For initializing the OpenVINO environment you should run thw script 'intel/openvino/bin/setupvars.sh'\n",
    "'''\n",
    "!bash intel/openvino/bin/setupvars.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LD_LIBRARY_PATH is /home/atugarev/intel/openvino_2020.1.016/opencv/lib:/home/atugarev/intel/openvino_2020.1.016/deployment_tools/ngraph/lib:/opt/intel/opencl:/home/atugarev/intel/openvino_2020.1.016/deployment_tools/inference_engine/external/hddl/lib:/home/atugarev/intel/openvino_2020.1.016/deployment_tools/inference_engine/external/gna/lib:/home/atugarev/intel/openvino_2020.1.016/deployment_tools/inference_engine/external/mkltiny_lnx/lib:/home/atugarev/intel/openvino_2020.1.016/deployment_tools/inference_engine/external/tbb/lib:/home/atugarev/intel/openvino_2020.1.016/deployment_tools/inference_engine/lib/intel64:\n",
      "\n",
      "PYTHONPATH is /home/atugarev/intel/openvino_2020.1.016/python/python3.6:/home/atugarev/intel/openvino_2020.1.016/python/python3:/home/atugarev/intel/openvino_2020.1.016/deployment_tools/open_model_zoo/tools/accuracy_checker:/home/atugarev/intel/openvino_2020.1.016/deployment_tools/model_optimizer:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAs you can see there are paths to the OpenVINO in LD_LIBRARY_PATH and PYTHONPATH variables.\\nSo you can already use the OpenVINO\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Lets try to check the environment'''\n",
    "!echo LD_LIBRARY_PATH is $LD_LIBRARY_PATH\n",
    "!echo\n",
    "!echo PYTHONPATH is $PYTHONPATH\n",
    "'''\n",
    "As you can see there are paths to the OpenVINO in LD_LIBRARY_PATH and PYTHONPATH variables.\n",
    "So you can already use the OpenVINO\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action-recognition-0001-decoder\r\n",
      "action-recognition-0001-encoder\r\n",
      "age-gender-recognition-retail-0013\r\n",
      "asl-recognition-0003\r\n",
      "driver-action-recognition-adas-0002-decoder\r\n",
      "driver-action-recognition-adas-0002-encoder\r\n",
      "emotions-recognition-retail-0003\r\n",
      "face-detection-adas-0001\r\n",
      "face-detection-adas-binary-0001\r\n",
      "face-detection-retail-0004\r\n",
      "face-detection-retail-0005\r\n",
      "face-reidentification-retail-0095\r\n",
      "facial-landmarks-35-adas-0002\r\n",
      "gaze-estimation-adas-0002\r\n",
      "handwritten-score-recognition-0003\r\n",
      "head-pose-estimation-adas-0001\r\n",
      "human-pose-estimation-0001\r\n",
      "image-retrieval-0001\r\n",
      "instance-segmentation-security-0010\r\n",
      "instance-segmentation-security-0050\r\n",
      "instance-segmentation-security-0083\r\n",
      "landmarks-regression-retail-0009\r\n",
      "license-plate-recognition-barrier-0001\r\n",
      "pedestrian-and-vehicle-detector-adas-0001\r\n",
      "pedestrian-detection-adas-0002\r\n",
      "pedestrian-detection-adas-binary-0001\r\n",
      "person-attributes-recognition-crossroad-0230\r\n",
      "person-detection-action-recognition-0005\r\n",
      "person-detection-action-recognition-0006\r\n",
      "person-detection-action-recognition-teacher-0002\r\n",
      "person-detection-asl-0001\r\n",
      "person-detection-raisinghand-recognition-0001\r\n",
      "person-detection-retail-0002\r\n",
      "person-detection-retail-0013\r\n",
      "person-reidentification-retail-0031\r\n",
      "person-reidentification-retail-0103\r\n",
      "person-reidentification-retail-0107\r\n",
      "person-reidentification-retail-0200\r\n",
      "person-vehicle-bike-detection-crossroad-0078\r\n",
      "person-vehicle-bike-detection-crossroad-1016\r\n",
      "product-detection-0001\r\n",
      "resnet18-xnor-binary-onnx-0001\r\n",
      "resnet50-binary-0001\r\n",
      "road-segmentation-adas-0001\r\n",
      "semantic-segmentation-adas-0001\r\n",
      "single-image-super-resolution-1032\r\n",
      "single-image-super-resolution-1033\r\n",
      "text-detection-0003\r\n",
      "text-detection-0004\r\n",
      "text-image-super-resolution-0001\r\n",
      "text-recognition-0012\r\n",
      "text-spotting-0001-detector\r\n",
      "text-spotting-0001-recognizer-decoder\r\n",
      "text-spotting-0001-recognizer-encoder\r\n",
      "vehicle-attributes-recognition-barrier-0039\r\n",
      "vehicle-detection-adas-0002\r\n",
      "vehicle-detection-adas-binary-0001\r\n",
      "vehicle-license-plate-detection-barrier-0106\r\n",
      "Sphereface\r\n",
      "alexnet\r\n",
      "brain-tumor-segmentation-0001\r\n",
      "brain-tumor-segmentation-0002\r\n",
      "caffenet\r\n",
      "ctdet_coco_dlav0_384\r\n",
      "ctdet_coco_dlav0_512\r\n",
      "ctpn\r\n",
      "deeplabv3\r\n",
      "densenet-121\r\n",
      "densenet-121-caffe2\r\n",
      "densenet-121-tf\r\n",
      "densenet-161\r\n",
      "densenet-161-tf\r\n",
      "densenet-169\r\n",
      "densenet-169-tf\r\n",
      "densenet-201\r\n",
      "efficientnet-b0\r\n",
      "efficientnet-b0-pytorch\r\n",
      "efficientnet-b0_auto_aug\r\n",
      "efficientnet-b5\r\n",
      "efficientnet-b5-pytorch\r\n",
      "efficientnet-b7-pytorch\r\n",
      "efficientnet-b7_auto_aug\r\n",
      "face-detection-retail-0044\r\n",
      "face-recognition-mobilefacenet-arcface\r\n",
      "face-recognition-resnet100-arcface\r\n",
      "face-recognition-resnet34-arcface\r\n",
      "face-recognition-resnet50-arcface\r\n",
      "facenet-20180408-102900\r\n",
      "faster_rcnn_inception_resnet_v2_atrous_coco\r\n",
      "faster_rcnn_inception_v2_coco\r\n",
      "faster_rcnn_resnet101_coco\r\n",
      "faster_rcnn_resnet50_coco\r\n",
      "googlenet-v1\r\n",
      "googlenet-v2\r\n",
      "googlenet-v3\r\n",
      "googlenet-v3-pytorch\r\n",
      "googlenet-v4\r\n",
      "human-pose-estimation-3d-0001\r\n",
      "inception-resnet-v2\r\n",
      "inception-resnet-v2-tf\r\n",
      "license-plate-recognition-barrier-0007\r\n",
      "mask_rcnn_inception_resnet_v2_atrous_coco\r\n",
      "mask_rcnn_inception_v2_coco\r\n",
      "mask_rcnn_resnet101_atrous_coco\r\n",
      "mask_rcnn_resnet50_atrous_coco\r\n",
      "mobilenet-ssd\r\n",
      "mobilenet-v1-0.25-128\r\n",
      "mobilenet-v1-0.50-160\r\n",
      "mobilenet-v1-0.50-224\r\n",
      "mobilenet-v1-1.0-224\r\n",
      "mobilenet-v1-1.0-224-tf\r\n",
      "mobilenet-v2\r\n",
      "mobilenet-v2-1.0-224\r\n",
      "mobilenet-v2-1.4-224\r\n",
      "mobilenet-v2-pytorch\r\n",
      "mtcnn-o\r\n",
      "mtcnn-p\r\n",
      "mtcnn-r\r\n",
      "octave-densenet-121-0.125\r\n",
      "octave-resnet-101-0.125\r\n",
      "octave-resnet-200-0.125\r\n",
      "octave-resnet-26-0.25\r\n",
      "octave-resnet-50-0.125\r\n",
      "octave-resnext-101-0.25\r\n",
      "octave-resnext-50-0.25\r\n",
      "octave-se-resnet-50-0.125\r\n",
      "resnet-101\r\n",
      "resnet-152\r\n",
      "resnet-50\r\n",
      "resnet-50-caffe2\r\n",
      "resnet-50-pytorch\r\n",
      "se-inception\r\n",
      "se-resnet-101\r\n",
      "se-resnet-152\r\n",
      "se-resnet-50\r\n",
      "se-resnext-101\r\n",
      "se-resnext-50\r\n",
      "single-human-pose-estimation-0001\r\n",
      "squeezenet1.0\r\n",
      "squeezenet1.1\r\n",
      "squeezenet1.1-caffe2\r\n",
      "ssd300\r\n",
      "ssd512\r\n",
      "ssd_mobilenet_v1_coco\r\n",
      "ssd_mobilenet_v1_fpn_coco\r\n",
      "ssd_mobilenet_v2_coco\r\n",
      "ssdlite_mobilenet_v2\r\n",
      "vehicle-license-plate-detection-barrier-0123\r\n",
      "vgg16\r\n",
      "vgg19\r\n",
      "vgg19-caffe2\r\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The OpenVINO package contains tools for easy download model from OpenModelZoo \n",
    "and converting the model to Intermediate Representation that OpenVINO supports\n",
    "\n",
    "To see all available models (both public open-sourse from original frameworks (TensorFlow, Caffe, MxNet, Pytorch e.t.c),\n",
    "and made in Intel).\n",
    "'''\n",
    "\n",
    "!python3 intel/openvino_2020.1.016/deployment_tools/open_model_zoo/tools/downloader/info_dumper.py --print_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################|| Downloading models ||################\n",
      "\n",
      "========== Downloading /home/atugarev/public/ssd_mobilenet_v1_coco/ssd_mobilenet_v1_coco.tar.gz\n",
      "... 100%, 74747 KB, 1592 KB/s, 46 seconds passed\n",
      "\n",
      "################|| Post-processing ||################\n",
      "\n",
      "========== Unpacking /home/atugarev/public/ssd_mobilenet_v1_coco/ssd_mobilenet_v1_coco.tar.gz\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Let's try to download an object detection model ssd_mobilenet_v1_coco\n",
    "'''\n",
    "!python3 intel/openvino_2020.1.016/deployment_tools/open_model_zoo/tools/downloader/downloader.py --name ssd_mobilenet_v1_coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 58140\r\n",
      "drwxr-xr-x 3 atugarev atugarev     4096 фев  1  2018 .\r\n",
      "drwxr-xr-x 3 atugarev atugarev     4096 янв 30 14:43 ..\r\n",
      "-rw-r--r-- 1 atugarev atugarev       77 фев  1  2018 checkpoint\r\n",
      "-rw-r--r-- 1 atugarev atugarev 29103956 фев  1  2018 frozen_inference_graph.pb\r\n",
      "-rw-r--r-- 1 atugarev atugarev 27380740 фев  1  2018 model.ckpt.data-00000-of-00001\r\n",
      "-rw-r--r-- 1 atugarev atugarev     8937 фев  1  2018 model.ckpt.index\r\n",
      "-rw-r--r-- 1 atugarev atugarev  3006546 фев  1  2018 model.ckpt.meta\r\n",
      "-rw-r--r-- 1 atugarev atugarev     4138 фев  1  2018 pipeline.config\r\n",
      "drwxr-xr-x 3 atugarev atugarev     4096 фев  1  2018 saved_model\r\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Model Downloader has downloaded the model to public/ssd_mobilenet_v1_coco/ssd_mobilenet_v1_coco_2018_01_28\n",
    "'''\n",
    "!ls -la public/ssd_mobilenet_v1_coco/ssd_mobilenet_v1_coco_2018_01_28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Converting ssd_mobilenet_v1_coco to IR (FP16)\n",
      "Conversion command: /home/atugarev/Developer/repositories/workbench/venv/bin/python3 -- /home/atugarev/intel/openvino_2020.1.016/deployment_tools/model_optimizer/mo.py --framework=tf --data_type=FP16 --output_dir=/home/atugarev/public/ssd_mobilenet_v1_coco/FP16 --model_name=ssd_mobilenet_v1_coco --reverse_input_channels '--input_shape=[1,300,300,3]' --input=image_tensor --output=detection_scores,detection_boxes,num_detections --transformations_config=/home/atugarev/intel/openvino_2020.1.016/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json --tensorflow_object_detection_api_pipeline_config=/home/atugarev/public/ssd_mobilenet_v1_coco/ssd_mobilenet_v1_coco_2018_01_28/pipeline.config --input_model=/home/atugarev/public/ssd_mobilenet_v1_coco/ssd_mobilenet_v1_coco_2018_01_28/frozen_inference_graph.pb\n",
      "\n",
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/atugarev/public/ssd_mobilenet_v1_coco/ssd_mobilenet_v1_coco_2018_01_28/frozen_inference_graph.pb\n",
      "\t- Path for generated IR: \t/home/atugarev/public/ssd_mobilenet_v1_coco/FP16\n",
      "\t- IR output name: \tssd_mobilenet_v1_coco\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \timage_tensor\n",
      "\t- Output layers: \tdetection_scores,detection_boxes,num_detections\n",
      "\t- Input shapes: \t[1,300,300,3]\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP16\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tTrue\n",
      "TensorFlow specific parameters:\n",
      "\t- Input model in text protobuf format: \tFalse\n",
      "\t- Path to model dump for TensorBoard: \tNone\n",
      "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
      "\t- Update the configuration file with input/output node names: \tNone\n",
      "\t- Use configuration file used to generate the model with Object Detection API: \t/home/atugarev/public/ssd_mobilenet_v1_coco/ssd_mobilenet_v1_coco_2018_01_28/pipeline.config\n",
      "\t- Operations to offload: \tNone\n",
      "\t- Patterns to offload: \tNone\n",
      "\t- Use the config file: \tNone\n",
      "Model Optimizer version: \t2020.1.0-55-g3b9c198827\n",
      "The Preprocessor block has been removed. Only nodes performing mean value subtraction and scaling (if applicable) are kept.\n",
      "\n",
      "[ SUCCESS ] Generated IR version 10 model.\n",
      "[ SUCCESS ] XML file: /home/atugarev/public/ssd_mobilenet_v1_coco/FP16/ssd_mobilenet_v1_coco.xml\n",
      "[ SUCCESS ] BIN file: /home/atugarev/public/ssd_mobilenet_v1_coco/FP16/ssd_mobilenet_v1_coco.bin\n",
      "[ SUCCESS ] Total execution time: 24.86 seconds. \n",
      "[ SUCCESS ] Memory consumed: 464 MB. \n",
      "\n",
      "========= Converting ssd_mobilenet_v1_coco to IR (FP32)\n",
      "Conversion command: /home/atugarev/Developer/repositories/workbench/venv/bin/python3 -- /home/atugarev/intel/openvino_2020.1.016/deployment_tools/model_optimizer/mo.py --framework=tf --data_type=FP32 --output_dir=/home/atugarev/public/ssd_mobilenet_v1_coco/FP32 --model_name=ssd_mobilenet_v1_coco --reverse_input_channels '--input_shape=[1,300,300,3]' --input=image_tensor --output=detection_scores,detection_boxes,num_detections --transformations_config=/home/atugarev/intel/openvino_2020.1.016/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json --tensorflow_object_detection_api_pipeline_config=/home/atugarev/public/ssd_mobilenet_v1_coco/ssd_mobilenet_v1_coco_2018_01_28/pipeline.config --input_model=/home/atugarev/public/ssd_mobilenet_v1_coco/ssd_mobilenet_v1_coco_2018_01_28/frozen_inference_graph.pb\n",
      "\n",
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/atugarev/public/ssd_mobilenet_v1_coco/ssd_mobilenet_v1_coco_2018_01_28/frozen_inference_graph.pb\n",
      "\t- Path for generated IR: \t/home/atugarev/public/ssd_mobilenet_v1_coco/FP32\n",
      "\t- IR output name: \tssd_mobilenet_v1_coco\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \timage_tensor\n",
      "\t- Output layers: \tdetection_scores,detection_boxes,num_detections\n",
      "\t- Input shapes: \t[1,300,300,3]\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tTrue\n",
      "TensorFlow specific parameters:\n",
      "\t- Input model in text protobuf format: \tFalse\n",
      "\t- Path to model dump for TensorBoard: \tNone\n",
      "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
      "\t- Update the configuration file with input/output node names: \tNone\n",
      "\t- Use configuration file used to generate the model with Object Detection API: \t/home/atugarev/public/ssd_mobilenet_v1_coco/ssd_mobilenet_v1_coco_2018_01_28/pipeline.config\n",
      "\t- Operations to offload: \tNone\n",
      "\t- Patterns to offload: \tNone\n",
      "\t- Use the config file: \tNone\n",
      "Model Optimizer version: \t2020.1.0-55-g3b9c198827\n",
      "The Preprocessor block has been removed. Only nodes performing mean value subtraction and scaling (if applicable) are kept.\n",
      "\n",
      "[ SUCCESS ] Generated IR version 10 model.\n",
      "[ SUCCESS ] XML file: /home/atugarev/public/ssd_mobilenet_v1_coco/FP32/ssd_mobilenet_v1_coco.xml\n",
      "[ SUCCESS ] BIN file: /home/atugarev/public/ssd_mobilenet_v1_coco/FP32/ssd_mobilenet_v1_coco.bin\n",
      "[ SUCCESS ] Total execution time: 24.86 seconds. \n",
      "[ SUCCESS ] Memory consumed: 466 MB. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "But the Model Downloader downloaded the model in TensorFlow format.\n",
    "You need convert this model to IR format. \n",
    "For this you need run converter script\n",
    "'''\n",
    "!python3 intel/openvino_2020.1.016/deployment_tools/open_model_zoo/tools/downloader/converter.py --name ssd_mobilenet_v1_coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 atugarev atugarev 27228836 янв 30 14:44 public/ssd_mobilenet_v1_coco/FP32/ssd_mobilenet_v1_coco.bin\r\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "converter script runs the Model Optimizer with right parameters to converting the model with to IR.\n",
    "Of course  we can run the Model Optimizer directly. But for this we need pass right arguments to the Model Optimizer.\n",
    "All information about converting\n",
    "'''\n",
    "!ls -la public/ssd_mobilenet_v1_coco/FP32/ssd_mobilenet_v1_coco.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 76\n",
      "drwxr-xr-x  6 atugarev atugarev 4096 янв 23 15:28 .\n",
      "drwxr-xr-x  8 atugarev atugarev 4096 янв 27 16:32 ..\n",
      "drwxr-xr-x  8 atugarev atugarev 4096 янв 27 17:07 extensions\n",
      "drwxr-xr-x  2 atugarev atugarev 4096 янв 23 15:27 install_prerequisites\n",
      "drwxr-xr-x 10 atugarev atugarev 4096 янв 27 17:07 mo\n",
      "-rwxr-xr-x  1 atugarev atugarev  932 янв 23 12:52 mo_caffe.py\n",
      "-rwxr-xr-x  1 atugarev atugarev  932 янв 23 12:52 mo_kaldi.py\n",
      "-rwxr-xr-x  1 atugarev atugarev  932 янв 23 12:52 mo_mxnet.py\n",
      "-rwxr-xr-x  1 atugarev atugarev  929 янв 23 12:52 mo_onnx.py\n",
      "-rwxr-xr-x  1 atugarev atugarev  999 янв 23 12:52 mo.py\n",
      "-rwxr-xr-x  1 atugarev atugarev  923 янв 23 12:52 mo_tf.py\n",
      "-rw-r--r--  1 atugarev atugarev   63 янв 23 12:52 requirements_caffe.txt\n",
      "-rw-r--r--  1 atugarev atugarev   47 янв 23 12:52 requirements_kaldi.txt\n",
      "-rw-r--r--  1 atugarev atugarev   68 янв 23 12:52 requirements_mxnet.txt\n",
      "-rw-r--r--  1 atugarev atugarev   59 янв 23 12:52 requirements_onnx.txt\n",
      "-rw-r--r--  1 atugarev atugarev   72 янв 23 12:52 requirements_tf.txt\n",
      "-rw-r--r--  1 atugarev atugarev  121 янв 23 12:52 requirements.txt\n",
      "drwxr-xr-x  3 atugarev atugarev 4096 янв 23 15:28 tf_call_ie_layer\n",
      "-rw-r--r--  1 atugarev atugarev   49 янв 23 12:52 version.txt\n",
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/atugarev/public/ssd_mobilenet_v1_coco/ssd_mobilenet_v1_coco_2018_01_28/frozen_inference_graph.pb\n",
      "\t- Path for generated IR: \t/home/atugarev/public/ssd_mobilenet_v1_coco/MY/FP32\n",
      "\t- IR output name: \tssd_mobilenet_v1_coco\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \timage_tensor\n",
      "\t- Output layers: \tdetection_scores,detection_boxes,num_detections\n",
      "\t- Input shapes: \t[1,300,300,3]\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP16\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tTrue\n",
      "TensorFlow specific parameters:\n",
      "\t- Input model in text protobuf format: \tFalse\n",
      "\t- Path to model dump for TensorBoard: \tNone\n",
      "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
      "\t- Update the configuration file with input/output node names: \tNone\n",
      "\t- Use configuration file used to generate the model with Object Detection API: \t/home/atugarev/public/ssd_mobilenet_v1_coco/ssd_mobilenet_v1_coco_2018_01_28/pipeline.config\n",
      "\t- Operations to offload: \tNone\n",
      "\t- Patterns to offload: \tNone\n",
      "\t- Use the config file: \tNone\n",
      "Model Optimizer version: \t2020.1.0-55-g3b9c198827\n",
      "The Preprocessor block has been removed. Only nodes performing mean value subtraction and scaling (if applicable) are kept.\n",
      "\n",
      "[ SUCCESS ] Generated IR version 10 model.\n",
      "[ SUCCESS ] XML file: /home/atugarev/public/ssd_mobilenet_v1_coco/MY/FP32/ssd_mobilenet_v1_coco.xml\n",
      "[ SUCCESS ] BIN file: /home/atugarev/public/ssd_mobilenet_v1_coco/MY/FP32/ssd_mobilenet_v1_coco.bin\n",
      "[ SUCCESS ] Total execution time: 24.45 seconds. \n",
      "[ SUCCESS ] Memory consumed: 466 MB. \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "You can find a command of running OpenVINO Model Optimizer in the output of the converter.py script.\n",
    "You can try this command:\n",
    "'''\n",
    "!python3 intel/openvino_2020.1.016/deployment_tools/model_optimizer/mo.py --framework=tf --data_type=FP16 --output_dir=/home/atugarev/public/ssd_mobilenet_v1_coco/MY/FP32 --model_name=ssd_mobilenet_v1_coco --reverse_input_channels '--input_shape=[1,300,300,3]' --input=image_tensor --output=detection_scores,detection_boxes,num_detections --transformations_config=/home/atugarev/intel/openvino_2020.1.016/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json --tensorflow_object_detection_api_pipeline_config=/home/atugarev/public/ssd_mobilenet_v1_coco/ssd_mobilenet_v1_coco_2018_01_28/pipeline.config --input_model=/home/atugarev/public/ssd_mobilenet_v1_coco/ssd_mobilenet_v1_coco_2018_01_28/frozen_inference_graph.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 1/11] Parsing and validating input arguments\n",
      "[ INFO ] Parsing input parameters\n",
      "\n",
      "benchmark_app [OPTION]\n",
      "Options:\n",
      "\n",
      "    -h, --help                Print a usage message\n",
      "    -i \"<path>\"               Optional. Path to a folder with images and/or binaries or to specific image or binary file.\n",
      "    -m \"<path>\"               Required. Path to an .xml file with a trained model or to a .blob files with a trained compiled model\n",
      "    -d \"<device>\"             Optional. Specify a target device to infer on (the list of available devices is shown below). Default value is CPU. Use \"-d HETERO:<comma-separated_devices_list>\" format to specify HETERO plugin. Use \"-d MULTI:<comma-separated_devices_list>\" format to specify MULTI plugin. The application looks for a suitable plugin for the specified device.\n",
      "    -l \"<absolute_path>\"      Required for CPU custom layers. Absolute path to a shared library with the kernels implementations.\n",
      "          Or\n",
      "    -c \"<absolute_path>\"      Required for GPU custom kernels. Absolute path to an .xml file with the kernels description.\n",
      "    -api \"<sync/async>\"       Optional. Enable Sync/Async API. Default value is \"async\".\n",
      "    -niter \"<integer>\"        Optional. Number of iterations. If not specified, the number of iterations is calculated depending on a device.\n",
      "    -nireq \"<integer>\"        Optional. Number of infer requests. Default value is determined automatically for device.\n",
      "    -b \"<integer>\"            Optional. Batch size value. If not specified, the batch size value is determined from Intermediate Representation.\n",
      "    -stream_output            Optional. Print progress as a plain text. When specified, an interactive progress bar is replaced with a multiline output.\n",
      "    -t                        Optional. Time in seconds to execute topology.\n",
      "    -progress                 Optional. Show progress bar (can affect performance measurement). Default values is \"false\".\n",
      "\n",
      "  device-specific performance options:\n",
      "    -nstreams \"<integer>\"     Optional. Number of streams to use for inference on the CPU or/and GPU in throughput mode (for HETERO and MULTI device cases use format <dev1>:<nstreams1>,<dev2>:<nstreams2> or just <nstreams>). Default value is determined automatically for a device.Please note that although the automatic selection usually provides a reasonable performance, it still may be non - optimal for some cases, especially for very small networks. See sample's README for more details.\n",
      "    -nthreads \"<integer>\"     Optional. Number of threads to use for inference on the CPU (including HETERO and MULTI cases).\n",
      "    -pin \"YES\"/\"NO\"           Optional. Enable threads->cores (\"YES\", default), threads->(NUMA)nodes (\"NUMA\") or completely disable (\"NO\") CPU threads pinning for CPU-involved inference.\n",
      "\n",
      "  Statistics dumping options:\n",
      "    -report_type \"<type>\"     Optional. Enable collecting statistics report. \"no_counters\" report contains configuration options specified, resulting FPS and latency. \"average_counters\" report extends \"no_counters\" report and additionally includes average PM counters values for each layer from the network. \"detailed_counters\" report extends \"average_counters\" report and additionally includes per-layer PM counters and latency for each executed infer request.\n",
      "    -report_folder            Optional. Path to a folder where statistics report is stored.\n",
      "    -exec_graph_path          Optional. Path to a file where to store executable graph information serialized.\n",
      "    -pc                       Optional. Report performance counters.\n",
      "\n",
      "Available target devices:  CPU  GPU  MYRIAD.3.1-ma2480  MYRIAD.3.2-ma2480  MYRIAD.5.1-ma2480  MYRIAD.5.2-ma2480  MYRIAD.7.1-ma2480  MYRIAD.7.2-ma2480  MYRIAD.9.1-ma2480  MYRIAD.9.2-ma2480"
     ]
    }
   ],
   "source": [
    "!intel/openvino_2020.1.016/deployment_tools/inference_engine/samples/cpp/build/intel64/Release/benchmark_app -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 1/11] Parsing and validating input arguments\n",
      "[ INFO ] Parsing input parameters\n",
      "[ WARNING ] -nstreams default value is determined automatically for a device. Although the automatic selection usually provides a reasonable performance,but it still may be non-optimal for some cases, for more information look at README.\n",
      "\n",
      "[Step 2/11] Loading Inference Engine\n",
      "[ INFO ] InferenceEngine: \n",
      "\tAPI version ............ 2.1\n",
      "\tBuild .................. 37919\n",
      "\tDescription ....... API\n",
      "[ INFO ] Device info: \n",
      "\tCPU\n",
      "\tMKLDNNPlugin version ......... 2.1\n",
      "\tBuild ........... 37919\n",
      "\n",
      "[Step 3/11] Setting device configuration\n",
      "[Step 4/11] Reading the Intermediate Representation network\n",
      "[ INFO ] Loading network files\n",
      "[ INFO ] Read network took 89.74 ms\n",
      "[Step 5/11] Resizing network to match image sizes and given batch\n",
      "[ INFO ] Network batch size: 1, precision: MIXED\n",
      "[Step 6/11] Configuring input of the model\n",
      "[Step 7/11] Loading the model to the device\n",
      "[ INFO ] Load network took 319.25 ms\n",
      "[Step 8/11] Setting optimal runtime parameters\n",
      "[Step 9/11] Creating infer requests and filling input blobs with images\n",
      "[ INFO ] Network input 'image_tensor' precision U8, dimensions (NCHW): 1 3 300 300 \n",
      "[ WARNING ] No input files were given: all inputs will be filled with random values!\n",
      "[ INFO ] Infer Request 0 filling\n",
      "[ INFO ] Fill input 'image_tensor' with random values (image is expected)\n",
      "[ INFO ] Infer Request 1 filling\n",
      "[ INFO ] Fill input 'image_tensor' with random values (image is expected)\n",
      "[ INFO ] Infer Request 2 filling\n",
      "[ INFO ] Fill input 'image_tensor' with random values (image is expected)\n",
      "[ INFO ] Infer Request 3 filling\n",
      "[ INFO ] Fill input 'image_tensor' with random values (image is expected)\n",
      "[Step 10/11] Measuring performance (Start inference asyncronously, 4 inference requests using 4 streams for CPU, limits: 60000 ms duration)\n",
      "\n",
      "[Step 11/11] Dumping statistics report\n",
      "Count:      8376 iterations\n",
      "Duration:   60025.65 ms\n",
      "Latency:    27.98 ms\n",
      "Throughput: 139.54 FPS\n",
      "Peak Virtual Memory (VmPeak) Size, kBytes: 1448124\n",
      "Peak Resident Memory (VmHWM) Size, kBytes:  298732\n"
     ]
    }
   ],
   "source": [
    "!intel/openvino_2020.1.016/deployment_tools/inference_engine/samples/cpp/build/intel64/Release/benchmark_app -m /home/atugarev/public/ssd_mobilenet_v1_coco/MY/FP32/ssd_mobilenet_v1_coco.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
