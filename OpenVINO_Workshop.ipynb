{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pictures/openvino_start.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 0: Register and Set Up Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of the workshop is initializing the OpenVINO™ environment in this Jupyter notebook. \n",
    "The OpenVINO™ 2020.1 package have been installed to `intel/openvino/` already.\n",
    "\n",
    "To initialize the OpenVINO™ environment, run the `intel/openvino/bin/setupvars.sh` script.\n",
    "If the prerequisite steps have been done right, you will see the output: \n",
    "\n",
    "```\n",
    "[setupvars.sh] OpenVINO environment initialized\n",
    "OpenVINO Inference Engine version is: 2.1.37988\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setupvars.sh] OpenVINO environment initialized\n",
      "OpenVINO Inference Engine version: 2.1.37988\n"
     ]
    }
   ],
   "source": [
    "!bash ~/intel/openvino/bin/setupvars.sh\n",
    "\n",
    "from openvino import inference_engine as ie\n",
    "print('OpenVINO Inference Engine version: {}'.format(ie.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda\n",
    "\n",
    "##  1. [Introduction](#s1)\n",
    "\n",
    "##  2. [What is SSD MobileNet V2?](#s2)\n",
    "\n",
    "##  3. [Where Can I Find the Model?](#s3)\n",
    "\n",
    "##  4. [Infer SSD MobileNet V2 on TensorFlow](#s4)\n",
    "\n",
    "##  5. [Infer on Real Data on TensorFlow](#s5)\n",
    "\n",
    "##  6. [OpenVINO™ Overview](#s6)\n",
    "\n",
    "##  7. [Model Optimizer - Entry to OpenVINO™](#s7)\n",
    "\n",
    "##  8. [Inference of SSD MobileNet V2 on OpenVINO™ Inference Engine](#s8)\n",
    "\n",
    "##  9. [Accuracy Checker - OpenVINO&trade; Accuracy Validation Framework](#s9)\n",
    "\n",
    "## 10. [Quantize the Model to Low Precision](#s10)\n",
    "\n",
    "## 11. [Post-Trainig Optimization Toolkit](#s11)\n",
    "\n",
    "## 12. [AccuracyAware Algorithm](#s12)\n",
    "\n",
    "## 13. [VNNI - Deep Learning Boost](#s13)\n",
    "\n",
    "## 14. [Get Even Better Performance](#s14)\n",
    "\n",
    "## 15. [Practice](#s15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Introduction<a id='s1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Gartner Says Global Artificial Intelligence Business Value to Reach 1.2 Trillion in 2018](https://www.gartner.com/en/newsroom/press-releases/2018-04-25-gartner-says-global-artificial-intelligence-business-value-to-reach-1-point-2-trillion-in-2018)\n",
    "Global business value derived from artificial intelligence (AI) is projected to total 1.2 trillion dollars in 2018, an increase of 70 percent from 2017, according to Gartner, Inc. AI-derived business value is forecast to reach $3.9 trillion in 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pictures/training_vs_inference.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ДИТ Москвы приобрел технологию поиска лиц в видеопотоке у компании Ntechlab](https://rb.ru/news/ntechlab-moscow/)\n",
    "Начальная конкурсная цена на разработку составляла 200 миллионов рублей, сумму контракта стороны не назвали."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pictures/about_vino.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostly for working with paths: os.path\n",
    "import os\n",
    "\n",
    "# working with arrays\n",
    "import numpy as np \n",
    "\n",
    "# path to data for the workshop\n",
    "WORKSHOP_DATA_PATH = os.path.join('.', 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference in 6 Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once [OpenVINO™](https://docs.openvinotoolkit.org/) is installed, you can run an inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prob': array([[[[4.83251752e-05]],\n",
       " \n",
       "         [[2.36514883e-04]],\n",
       " \n",
       "         [[2.61827465e-03]],\n",
       " \n",
       "         [[1.65878527e-03]],\n",
       " \n",
       "         [[5.61648654e-03]],\n",
       " \n",
       "         [[7.85280485e-03]],\n",
       " \n",
       "         [[6.94619119e-03]],\n",
       " \n",
       "         [[2.10561284e-05]],\n",
       " \n",
       "         [[2.11599618e-05]],\n",
       " \n",
       "         [[1.42805031e-04]],\n",
       " \n",
       "         [[5.64713519e-05]],\n",
       " \n",
       "         [[6.45918990e-05]],\n",
       " \n",
       "         [[3.56437995e-05]],\n",
       " \n",
       "         [[1.36634088e-04]],\n",
       " \n",
       "         [[1.41603814e-04]],\n",
       " \n",
       "         [[2.77795971e-05]],\n",
       " \n",
       "         [[2.26017619e-05]],\n",
       " \n",
       "         [[4.43375102e-05]],\n",
       " \n",
       "         [[1.84868128e-04]],\n",
       " \n",
       "         [[6.72746392e-05]],\n",
       " \n",
       "         [[1.85742188e-04]],\n",
       " \n",
       "         [[1.86057572e-04]],\n",
       " \n",
       "         [[1.18623924e-04]],\n",
       " \n",
       "         [[1.47054307e-04]],\n",
       " \n",
       "         [[1.92671272e-04]],\n",
       " \n",
       "         [[2.19571404e-04]],\n",
       " \n",
       "         [[1.76366404e-04]],\n",
       " \n",
       "         [[2.04742988e-04]],\n",
       " \n",
       "         [[5.09402656e-04]],\n",
       " \n",
       "         [[2.49441713e-04]],\n",
       " \n",
       "         [[1.60853269e-05]],\n",
       " \n",
       "         [[8.68120347e-04]],\n",
       " \n",
       "         [[7.09102897e-05]],\n",
       " \n",
       "         [[2.88411218e-04]],\n",
       " \n",
       "         [[4.76115989e-03]],\n",
       " \n",
       "         [[3.42266285e-05]],\n",
       " \n",
       "         [[3.95330688e-04]],\n",
       " \n",
       "         [[1.72615619e-05]],\n",
       " \n",
       "         [[7.05561135e-04]],\n",
       " \n",
       "         [[2.73496189e-05]],\n",
       " \n",
       "         [[1.56163936e-04]],\n",
       " \n",
       "         [[1.46631864e-04]],\n",
       " \n",
       "         [[6.46043118e-05]],\n",
       " \n",
       "         [[2.54545066e-05]],\n",
       " \n",
       "         [[1.03718630e-04]],\n",
       " \n",
       "         [[7.92851133e-05]],\n",
       " \n",
       "         [[1.32300600e-04]],\n",
       " \n",
       "         [[2.51124700e-04]],\n",
       " \n",
       "         [[2.51306883e-05]],\n",
       " \n",
       "         [[2.10709666e-04]],\n",
       " \n",
       "         [[3.62037419e-04]],\n",
       " \n",
       "         [[3.56345190e-05]],\n",
       " \n",
       "         [[8.56663508e-04]],\n",
       " \n",
       "         [[3.59925063e-04]],\n",
       " \n",
       "         [[6.28789654e-04]],\n",
       " \n",
       "         [[2.39453075e-04]],\n",
       " \n",
       "         [[1.93253523e-04]],\n",
       " \n",
       "         [[2.47402695e-05]],\n",
       " \n",
       "         [[1.36125745e-04]],\n",
       " \n",
       "         [[3.80343222e-03]],\n",
       " \n",
       "         [[5.29871788e-03]],\n",
       " \n",
       "         [[2.42799215e-04]],\n",
       " \n",
       "         [[1.29076291e-03]],\n",
       " \n",
       "         [[5.79560176e-04]],\n",
       " \n",
       "         [[6.50161412e-04]],\n",
       " \n",
       "         [[2.39769579e-03]],\n",
       " \n",
       "         [[1.07558246e-03]],\n",
       " \n",
       "         [[5.23556773e-05]],\n",
       " \n",
       "         [[4.52026608e-04]],\n",
       " \n",
       "         [[9.89268767e-04]],\n",
       " \n",
       "         [[3.06806236e-04]],\n",
       " \n",
       "         [[5.83220180e-03]],\n",
       " \n",
       "         [[5.97173530e-05]],\n",
       " \n",
       "         [[5.79649489e-03]],\n",
       " \n",
       "         [[1.06270738e-04]],\n",
       " \n",
       "         [[5.70949400e-04]],\n",
       " \n",
       "         [[3.62281251e-04]],\n",
       " \n",
       "         [[1.99413253e-03]],\n",
       " \n",
       "         [[1.42191192e-02]],\n",
       " \n",
       "         [[5.37361670e-03]],\n",
       " \n",
       "         [[3.38067512e-05]],\n",
       " \n",
       "         [[1.50097621e-04]],\n",
       " \n",
       "         [[8.74164252e-05]],\n",
       " \n",
       "         [[2.70798810e-05]],\n",
       " \n",
       "         [[2.24423675e-05]],\n",
       " \n",
       "         [[3.41280611e-05]],\n",
       " \n",
       "         [[5.34277970e-05]],\n",
       " \n",
       "         [[6.73761097e-05]],\n",
       " \n",
       "         [[1.86663347e-05]],\n",
       " \n",
       "         [[8.32354126e-05]],\n",
       " \n",
       "         [[2.44999119e-05]],\n",
       " \n",
       "         [[8.14489031e-05]],\n",
       " \n",
       "         [[7.95718151e-05]],\n",
       " \n",
       "         [[2.37706445e-05]],\n",
       " \n",
       "         [[4.70417843e-04]],\n",
       " \n",
       "         [[2.11443476e-05]],\n",
       " \n",
       "         [[1.83240816e-04]],\n",
       " \n",
       "         [[1.87219775e-05]],\n",
       " \n",
       "         [[3.50374539e-05]],\n",
       " \n",
       "         [[2.69355311e-04]],\n",
       " \n",
       "         [[7.10443855e-05]],\n",
       " \n",
       "         [[5.46210213e-05]],\n",
       " \n",
       "         [[6.49917783e-05]],\n",
       " \n",
       "         [[2.52477638e-03]],\n",
       " \n",
       "         [[6.46769040e-05]],\n",
       " \n",
       "         [[1.27024869e-05]],\n",
       " \n",
       "         [[6.63980609e-05]],\n",
       " \n",
       "         [[1.13199512e-02]],\n",
       " \n",
       "         [[6.68155262e-04]],\n",
       " \n",
       "         [[2.52109865e-04]],\n",
       " \n",
       "         [[3.36984842e-04]],\n",
       " \n",
       "         [[1.34402439e-01]],\n",
       " \n",
       "         [[5.62361209e-04]],\n",
       " \n",
       "         [[1.72872550e-03]],\n",
       " \n",
       "         [[2.02635187e-03]],\n",
       " \n",
       "         [[4.20723198e-04]],\n",
       " \n",
       "         [[1.78085276e-04]],\n",
       " \n",
       "         [[1.87363487e-03]],\n",
       " \n",
       "         [[3.73583680e-05]],\n",
       " \n",
       "         [[1.34526243e-04]],\n",
       " \n",
       "         [[5.20156609e-05]],\n",
       " \n",
       "         [[2.86890918e-05]],\n",
       " \n",
       "         [[1.85461358e-05]],\n",
       " \n",
       "         [[6.37294652e-05]],\n",
       " \n",
       "         [[1.19530814e-04]],\n",
       " \n",
       "         [[4.03429411e-04]],\n",
       " \n",
       "         [[6.82803849e-03]],\n",
       " \n",
       "         [[2.32676481e-04]],\n",
       " \n",
       "         [[4.11559013e-04]],\n",
       " \n",
       "         [[2.96820392e-04]],\n",
       " \n",
       "         [[1.49084735e-04]],\n",
       " \n",
       "         [[5.47407217e-05]],\n",
       " \n",
       "         [[2.44822673e-04]],\n",
       " \n",
       "         [[4.03457874e-04]],\n",
       " \n",
       "         [[2.55784653e-05]],\n",
       " \n",
       "         [[4.02030622e-04]],\n",
       " \n",
       "         [[1.97555564e-05]],\n",
       " \n",
       "         [[7.27827210e-05]],\n",
       " \n",
       "         [[3.51026065e-05]],\n",
       " \n",
       "         [[5.39460125e-05]],\n",
       " \n",
       "         [[2.22046529e-05]],\n",
       " \n",
       "         [[1.46733364e-04]],\n",
       " \n",
       "         [[1.99363021e-05]],\n",
       " \n",
       "         [[8.08735422e-05]],\n",
       " \n",
       "         [[7.66990051e-05]],\n",
       " \n",
       "         [[3.96751930e-05]],\n",
       " \n",
       "         [[1.50504333e-04]],\n",
       " \n",
       "         [[1.60228158e-03]],\n",
       " \n",
       "         [[2.70000077e-04]],\n",
       " \n",
       "         [[1.29724666e-03]],\n",
       " \n",
       "         [[6.40645521e-05]],\n",
       " \n",
       "         [[5.62456953e-05]],\n",
       " \n",
       "         [[2.30772093e-05]],\n",
       " \n",
       "         [[1.46010832e-04]],\n",
       " \n",
       "         [[4.00188328e-05]],\n",
       " \n",
       "         [[4.44615762e-05]],\n",
       " \n",
       "         [[2.41843409e-05]],\n",
       " \n",
       "         [[2.33186602e-05]],\n",
       " \n",
       "         [[1.97447644e-05]],\n",
       " \n",
       "         [[6.35476972e-05]],\n",
       " \n",
       "         [[1.51282702e-05]],\n",
       " \n",
       "         [[4.08489432e-05]],\n",
       " \n",
       "         [[1.38294403e-04]],\n",
       " \n",
       "         [[3.50535629e-05]],\n",
       " \n",
       "         [[9.92208661e-05]],\n",
       " \n",
       "         [[8.09812846e-05]],\n",
       " \n",
       "         [[4.32321103e-05]],\n",
       " \n",
       "         [[2.45139599e-05]],\n",
       " \n",
       "         [[3.05403082e-05]],\n",
       " \n",
       "         [[4.69445768e-05]],\n",
       " \n",
       "         [[2.61612804e-05]],\n",
       " \n",
       "         [[1.21159494e-04]],\n",
       " \n",
       "         [[8.11418140e-05]],\n",
       " \n",
       "         [[1.38961777e-05]],\n",
       " \n",
       "         [[1.50652104e-05]],\n",
       " \n",
       "         [[1.71853153e-05]],\n",
       " \n",
       "         [[1.61716926e-05]],\n",
       " \n",
       "         [[2.96748221e-05]],\n",
       " \n",
       "         [[4.99405374e-04]],\n",
       " \n",
       "         [[1.27284493e-05]],\n",
       " \n",
       "         [[1.26979076e-05]],\n",
       " \n",
       "         [[1.43822490e-05]],\n",
       " \n",
       "         [[1.67814251e-05]],\n",
       " \n",
       "         [[2.14807224e-05]],\n",
       " \n",
       "         [[7.55032306e-05]],\n",
       " \n",
       "         [[3.40373772e-05]],\n",
       " \n",
       "         [[2.55073846e-05]],\n",
       " \n",
       "         [[2.18120069e-04]],\n",
       " \n",
       "         [[1.32420200e-05]],\n",
       " \n",
       "         [[7.89530750e-05]],\n",
       " \n",
       "         [[1.09758694e-04]],\n",
       " \n",
       "         [[3.17552331e-05]],\n",
       " \n",
       "         [[3.26068657e-05]],\n",
       " \n",
       "         [[1.99258484e-05]],\n",
       " \n",
       "         [[1.67435537e-05]],\n",
       " \n",
       "         [[1.82975637e-05]],\n",
       " \n",
       "         [[3.16501100e-05]],\n",
       " \n",
       "         [[2.09693408e-05]],\n",
       " \n",
       "         [[1.47649635e-05]],\n",
       " \n",
       "         [[6.59500583e-05]],\n",
       " \n",
       "         [[2.65609979e-05]],\n",
       " \n",
       "         [[1.98319303e-05]],\n",
       " \n",
       "         [[1.84816381e-05]],\n",
       " \n",
       "         [[2.81502027e-04]],\n",
       " \n",
       "         [[4.11250017e-04]],\n",
       " \n",
       "         [[4.23571691e-05]],\n",
       " \n",
       "         [[4.58906798e-05]],\n",
       " \n",
       "         [[2.01154053e-05]],\n",
       " \n",
       "         [[1.66722330e-05]],\n",
       " \n",
       "         [[1.07912660e-04]],\n",
       " \n",
       "         [[1.26066034e-05]],\n",
       " \n",
       "         [[2.73881687e-05]],\n",
       " \n",
       "         [[1.20818419e-04]],\n",
       " \n",
       "         [[4.17649171e-05]],\n",
       " \n",
       "         [[5.59638793e-05]],\n",
       " \n",
       "         [[3.06857291e-05]],\n",
       " \n",
       "         [[2.48562956e-05]],\n",
       " \n",
       "         [[8.85676127e-05]],\n",
       " \n",
       "         [[3.01298314e-05]],\n",
       " \n",
       "         [[1.65261699e-05]],\n",
       " \n",
       "         [[1.96211950e-05]],\n",
       " \n",
       "         [[6.78326032e-05]],\n",
       " \n",
       "         [[3.19550054e-05]],\n",
       " \n",
       "         [[1.28010448e-04]],\n",
       " \n",
       "         [[4.18966447e-05]],\n",
       " \n",
       "         [[1.91979871e-05]],\n",
       " \n",
       "         [[2.21770570e-05]],\n",
       " \n",
       "         [[1.26377090e-05]],\n",
       " \n",
       "         [[8.66161645e-05]],\n",
       " \n",
       "         [[3.88440021e-05]],\n",
       " \n",
       "         [[3.31689371e-05]],\n",
       " \n",
       "         [[1.67366725e-05]],\n",
       " \n",
       "         [[3.55600023e-05]],\n",
       " \n",
       "         [[4.07032712e-05]],\n",
       " \n",
       "         [[2.63869642e-05]],\n",
       " \n",
       "         [[2.81683151e-05]],\n",
       " \n",
       "         [[1.78746213e-05]],\n",
       " \n",
       "         [[1.40712355e-05]],\n",
       " \n",
       "         [[9.11986135e-05]],\n",
       " \n",
       "         [[8.75725891e-05]],\n",
       " \n",
       "         [[1.72803411e-05]],\n",
       " \n",
       "         [[5.70176162e-05]],\n",
       " \n",
       "         [[2.24114847e-05]],\n",
       " \n",
       "         [[1.26066034e-05]],\n",
       " \n",
       "         [[2.30893602e-05]],\n",
       " \n",
       "         [[2.90459611e-05]],\n",
       " \n",
       "         [[1.40136508e-05]],\n",
       " \n",
       "         [[2.02302945e-05]],\n",
       " \n",
       "         [[1.94058830e-05]],\n",
       " \n",
       "         [[3.34058786e-05]],\n",
       " \n",
       "         [[8.94264886e-05]],\n",
       " \n",
       "         [[7.51022599e-05]],\n",
       " \n",
       "         [[8.80581501e-05]],\n",
       " \n",
       "         [[1.31201878e-05]],\n",
       " \n",
       "         [[3.88629742e-05]],\n",
       " \n",
       "         [[1.26066034e-05]],\n",
       " \n",
       "         [[5.96680547e-05]],\n",
       " \n",
       "         [[2.62790290e-05]],\n",
       " \n",
       "         [[1.93134765e-05]],\n",
       " \n",
       "         [[2.56426774e-05]],\n",
       " \n",
       "         [[2.32272178e-05]],\n",
       " \n",
       "         [[1.31763381e-05]],\n",
       " \n",
       "         [[1.54688569e-05]],\n",
       " \n",
       "         [[4.88669684e-05]],\n",
       " \n",
       "         [[3.17232661e-05]],\n",
       " \n",
       "         [[4.54111796e-05]],\n",
       " \n",
       "         [[4.57432980e-05]],\n",
       " \n",
       "         [[1.80558181e-05]],\n",
       " \n",
       "         [[2.15451237e-05]],\n",
       " \n",
       "         [[5.30806486e-04]],\n",
       " \n",
       "         [[1.74555200e-04]],\n",
       " \n",
       "         [[4.33977148e-05]],\n",
       " \n",
       "         [[3.49568174e-04]],\n",
       " \n",
       "         [[1.12087560e-04]],\n",
       " \n",
       "         [[4.61405361e-05]],\n",
       " \n",
       "         [[3.53762989e-05]],\n",
       " \n",
       "         [[1.51274865e-03]],\n",
       " \n",
       "         [[4.88513091e-04]],\n",
       " \n",
       "         [[1.64917918e-04]],\n",
       " \n",
       "         [[1.28870204e-04]],\n",
       " \n",
       "         [[2.97134917e-04]],\n",
       " \n",
       "         [[4.72268672e-04]],\n",
       " \n",
       "         [[1.61835036e-04]],\n",
       " \n",
       "         [[1.75095149e-04]],\n",
       " \n",
       "         [[6.82355239e-05]],\n",
       " \n",
       "         [[3.04483547e-04]],\n",
       " \n",
       "         [[1.05055587e-04]],\n",
       " \n",
       "         [[4.17572301e-05]],\n",
       " \n",
       "         [[5.05214848e-04]],\n",
       " \n",
       "         [[4.81100178e-05]],\n",
       " \n",
       "         [[2.69192333e-05]],\n",
       " \n",
       "         [[5.02934563e-05]],\n",
       " \n",
       "         [[3.54332224e-05]],\n",
       " \n",
       "         [[2.10747632e-04]],\n",
       " \n",
       "         [[7.53782660e-05]],\n",
       " \n",
       "         [[1.08689761e-04]],\n",
       " \n",
       "         [[7.88710386e-05]],\n",
       " \n",
       "         [[6.04711764e-04]],\n",
       " \n",
       "         [[1.34533941e-04]],\n",
       " \n",
       "         [[1.90063627e-04]],\n",
       " \n",
       "         [[1.08414395e-04]],\n",
       " \n",
       "         [[6.33884454e-04]],\n",
       " \n",
       "         [[4.51826818e-05]],\n",
       " \n",
       "         [[5.16597705e-04]],\n",
       " \n",
       "         [[2.45760486e-04]],\n",
       " \n",
       "         [[6.02163200e-05]],\n",
       " \n",
       "         [[2.04691067e-04]],\n",
       " \n",
       "         [[4.06607520e-03]],\n",
       " \n",
       "         [[9.06238856e-04]],\n",
       " \n",
       "         [[6.41857623e-05]],\n",
       " \n",
       "         [[1.00829517e-02]],\n",
       " \n",
       "         [[5.90130396e-04]],\n",
       " \n",
       "         [[1.75013021e-03]],\n",
       " \n",
       "         [[1.78340473e-03]],\n",
       " \n",
       "         [[3.63546284e-03]],\n",
       " \n",
       "         [[8.40024033e-04]],\n",
       " \n",
       "         [[1.32590171e-03]],\n",
       " \n",
       "         [[4.90559405e-03]],\n",
       " \n",
       "         [[8.23034067e-03]],\n",
       " \n",
       "         [[2.25675787e-04]],\n",
       " \n",
       "         [[1.36436240e-04]],\n",
       " \n",
       "         [[3.47790156e-05]],\n",
       " \n",
       "         [[2.75185012e-05]],\n",
       " \n",
       "         [[3.41493906e-05]],\n",
       " \n",
       "         [[5.28411125e-04]],\n",
       " \n",
       "         [[4.59781659e-05]],\n",
       " \n",
       "         [[4.05041414e-04]],\n",
       " \n",
       "         [[3.66688793e-04]],\n",
       " \n",
       "         [[8.09148594e-04]],\n",
       " \n",
       "         [[1.09190529e-04]],\n",
       " \n",
       "         [[1.87837941e-04]],\n",
       " \n",
       "         [[4.92228100e-05]],\n",
       " \n",
       "         [[4.54038818e-05]],\n",
       " \n",
       "         [[8.50941360e-05]],\n",
       " \n",
       "         [[5.46163064e-04]],\n",
       " \n",
       "         [[2.84542562e-04]],\n",
       " \n",
       "         [[6.47371635e-05]],\n",
       " \n",
       "         [[6.64588180e-04]],\n",
       " \n",
       "         [[1.83276370e-05]],\n",
       " \n",
       "         [[2.09670015e-05]],\n",
       " \n",
       "         [[4.36189985e-05]],\n",
       " \n",
       "         [[3.80141937e-05]],\n",
       " \n",
       "         [[4.67775244e-05]],\n",
       " \n",
       "         [[4.49432227e-05]],\n",
       " \n",
       "         [[3.44289110e-05]],\n",
       " \n",
       "         [[3.16200603e-05]],\n",
       " \n",
       "         [[1.67788639e-05]],\n",
       " \n",
       "         [[2.53671933e-05]],\n",
       " \n",
       "         [[1.48977633e-05]],\n",
       " \n",
       "         [[3.09463721e-05]],\n",
       " \n",
       "         [[8.33254453e-05]],\n",
       " \n",
       "         [[5.10364953e-05]],\n",
       " \n",
       "         [[9.89409818e-05]],\n",
       " \n",
       "         [[6.35918914e-05]],\n",
       " \n",
       "         [[5.77430619e-05]],\n",
       " \n",
       "         [[2.84198522e-05]],\n",
       " \n",
       "         [[3.30134324e-04]],\n",
       " \n",
       "         [[5.16575528e-05]],\n",
       " \n",
       "         [[8.52023368e-05]],\n",
       " \n",
       "         [[5.35928084e-05]],\n",
       " \n",
       "         [[3.47954221e-04]],\n",
       " \n",
       "         [[3.51154798e-04]],\n",
       " \n",
       "         [[6.57989061e-04]],\n",
       " \n",
       "         [[1.91922853e-04]],\n",
       " \n",
       "         [[1.78769493e-04]],\n",
       " \n",
       "         [[1.59994524e-04]],\n",
       " \n",
       "         [[7.51431289e-05]],\n",
       " \n",
       "         [[1.46423306e-04]],\n",
       " \n",
       "         [[3.28638598e-05]],\n",
       " \n",
       "         [[1.61051124e-04]],\n",
       " \n",
       "         [[5.53610917e-05]],\n",
       " \n",
       "         [[4.95860950e-05]],\n",
       " \n",
       "         [[3.14257341e-05]],\n",
       " \n",
       "         [[5.46436313e-05]],\n",
       " \n",
       "         [[6.19327548e-05]],\n",
       " \n",
       "         [[6.88398359e-05]],\n",
       " \n",
       "         [[3.78897203e-05]],\n",
       " \n",
       "         [[1.17244483e-04]],\n",
       " \n",
       "         [[3.30606745e-05]],\n",
       " \n",
       "         [[4.52130262e-05]],\n",
       " \n",
       "         [[3.10945004e-04]],\n",
       " \n",
       "         [[6.43249878e-05]],\n",
       " \n",
       "         [[6.63464089e-05]],\n",
       " \n",
       "         [[3.15784746e-05]],\n",
       " \n",
       "         [[6.56187112e-05]],\n",
       " \n",
       "         [[6.55610420e-05]],\n",
       " \n",
       "         [[3.79584053e-05]],\n",
       " \n",
       "         [[1.19308963e-04]],\n",
       " \n",
       "         [[3.85676358e-05]],\n",
       " \n",
       "         [[6.25838700e-04]],\n",
       " \n",
       "         [[5.29498735e-04]],\n",
       " \n",
       "         [[7.67838210e-05]],\n",
       " \n",
       "         [[1.69146966e-04]],\n",
       " \n",
       "         [[6.27860209e-05]],\n",
       " \n",
       "         [[2.19833411e-04]],\n",
       " \n",
       "         [[9.43101244e-04]],\n",
       " \n",
       "         [[4.74945264e-04]],\n",
       " \n",
       "         [[1.02556485e-03]],\n",
       " \n",
       "         [[2.18974601e-04]],\n",
       " \n",
       "         [[1.72759255e-03]],\n",
       " \n",
       "         [[3.72855466e-05]],\n",
       " \n",
       "         [[1.00379926e-03]],\n",
       " \n",
       "         [[2.64479982e-04]],\n",
       " \n",
       "         [[5.57538042e-05]],\n",
       " \n",
       "         [[2.29016849e-04]],\n",
       " \n",
       "         [[7.08074134e-04]],\n",
       " \n",
       "         [[1.56336246e-05]],\n",
       " \n",
       "         [[2.73731828e-04]],\n",
       " \n",
       "         [[1.79962517e-05]],\n",
       " \n",
       "         [[2.61306483e-03]],\n",
       " \n",
       "         [[4.38978022e-05]],\n",
       " \n",
       "         [[4.51208471e-05]],\n",
       " \n",
       "         [[2.00240989e-04]],\n",
       " \n",
       "         [[3.71394213e-04]],\n",
       " \n",
       "         [[1.41523205e-05]],\n",
       " \n",
       "         [[1.43352527e-05]],\n",
       " \n",
       "         [[1.17758499e-03]],\n",
       " \n",
       "         [[3.28528159e-03]],\n",
       " \n",
       "         [[8.54305632e-04]],\n",
       " \n",
       "         [[2.47073453e-03]],\n",
       " \n",
       "         [[3.71785631e-04]],\n",
       " \n",
       "         [[2.11427873e-03]],\n",
       " \n",
       "         [[7.83780779e-05]],\n",
       " \n",
       "         [[2.51999973e-05]],\n",
       " \n",
       "         [[3.81755344e-05]],\n",
       " \n",
       "         [[1.57800107e-03]],\n",
       " \n",
       "         [[1.58887502e-04]],\n",
       " \n",
       "         [[2.74477206e-04]],\n",
       " \n",
       "         [[3.31791525e-05]],\n",
       " \n",
       "         [[2.43746588e-04]],\n",
       " \n",
       "         [[1.21146899e-04]],\n",
       " \n",
       "         [[1.42141216e-05]],\n",
       " \n",
       "         [[8.51506775e-05]],\n",
       " \n",
       "         [[3.50475821e-05]],\n",
       " \n",
       "         [[9.38102530e-05]],\n",
       " \n",
       "         [[3.84006853e-04]],\n",
       " \n",
       "         [[1.74295783e-05]],\n",
       " \n",
       "         [[7.08223041e-03]],\n",
       " \n",
       "         [[1.33551680e-03]],\n",
       " \n",
       "         [[9.50584217e-05]],\n",
       " \n",
       "         [[2.89008574e-04]],\n",
       " \n",
       "         [[4.21847537e-04]],\n",
       " \n",
       "         [[7.18828640e-04]],\n",
       " \n",
       "         [[2.40366298e-05]],\n",
       " \n",
       "         [[6.79648365e-05]],\n",
       " \n",
       "         [[8.29677811e-05]],\n",
       " \n",
       "         [[3.16043384e-03]],\n",
       " \n",
       "         [[3.99500459e-05]],\n",
       " \n",
       "         [[3.45682958e-04]],\n",
       " \n",
       "         [[3.37340287e-04]],\n",
       " \n",
       "         [[3.58449834e-05]],\n",
       " \n",
       "         [[1.37518195e-03]],\n",
       " \n",
       "         [[4.58919531e-05]],\n",
       " \n",
       "         [[4.66924394e-05]],\n",
       " \n",
       "         [[1.84241089e-05]],\n",
       " \n",
       "         [[2.30257909e-04]],\n",
       " \n",
       "         [[9.14481279e-05]],\n",
       " \n",
       "         [[2.23404975e-04]],\n",
       " \n",
       "         [[1.52366174e-05]],\n",
       " \n",
       "         [[2.57508975e-04]],\n",
       " \n",
       "         [[3.67052126e-04]],\n",
       " \n",
       "         [[5.24737952e-05]],\n",
       " \n",
       "         [[8.42856709e-04]],\n",
       " \n",
       "         [[2.40831054e-04]],\n",
       " \n",
       "         [[4.14119510e-04]],\n",
       " \n",
       "         [[2.81767687e-04]],\n",
       " \n",
       "         [[7.85492084e-05]],\n",
       " \n",
       "         [[4.12166628e-05]],\n",
       " \n",
       "         [[1.02551050e-04]],\n",
       " \n",
       "         [[2.09259291e-04]],\n",
       " \n",
       "         [[7.77395151e-04]],\n",
       " \n",
       "         [[3.43880092e-04]],\n",
       " \n",
       "         [[6.72059250e-05]],\n",
       " \n",
       "         [[3.68705078e-04]],\n",
       " \n",
       "         [[3.36825324e-05]],\n",
       " \n",
       "         [[4.71559848e-04]],\n",
       " \n",
       "         [[4.76167734e-05]],\n",
       " \n",
       "         [[1.30922026e-05]],\n",
       " \n",
       "         [[1.33193171e-04]],\n",
       " \n",
       "         [[5.93832170e-04]],\n",
       " \n",
       "         [[1.06412925e-04]],\n",
       " \n",
       "         [[2.36322798e-04]],\n",
       " \n",
       "         [[1.14339440e-04]],\n",
       " \n",
       "         [[7.01427343e-04]],\n",
       " \n",
       "         [[5.67677125e-05]],\n",
       " \n",
       "         [[6.53380237e-04]],\n",
       " \n",
       "         [[3.58516379e-04]],\n",
       " \n",
       "         [[1.20425003e-03]],\n",
       " \n",
       "         [[1.18204905e-03]],\n",
       " \n",
       "         [[5.96811995e-04]],\n",
       " \n",
       "         [[1.34095084e-04]],\n",
       " \n",
       "         [[4.11234912e-04]],\n",
       " \n",
       "         [[2.67811392e-05]],\n",
       " \n",
       "         [[4.54879446e-05]],\n",
       " \n",
       "         [[1.13927468e-03]],\n",
       " \n",
       "         [[1.67400249e-05]],\n",
       " \n",
       "         [[3.59390142e-05]],\n",
       " \n",
       "         [[6.42520608e-04]],\n",
       " \n",
       "         [[4.25458944e-04]],\n",
       " \n",
       "         [[3.35723744e-03]],\n",
       " \n",
       "         [[2.35840655e-03]],\n",
       " \n",
       "         [[3.01273772e-04]],\n",
       " \n",
       "         [[2.95806476e-05]],\n",
       " \n",
       "         [[2.35372383e-04]],\n",
       " \n",
       "         [[3.25959089e-04]],\n",
       " \n",
       "         [[4.37618728e-05]],\n",
       " \n",
       "         [[3.59810772e-04]],\n",
       " \n",
       "         [[8.79679632e-04]],\n",
       " \n",
       "         [[1.79667410e-03]],\n",
       " \n",
       "         [[2.03137552e-05]],\n",
       " \n",
       "         [[1.03221202e-04]],\n",
       " \n",
       "         [[1.46995053e-05]],\n",
       " \n",
       "         [[2.54953833e-04]],\n",
       " \n",
       "         [[2.41339629e-04]],\n",
       " \n",
       "         [[1.64046229e-04]],\n",
       " \n",
       "         [[9.90028493e-05]],\n",
       " \n",
       "         [[1.64994144e-05]],\n",
       " \n",
       "         [[1.06479926e-02]],\n",
       " \n",
       "         [[6.51193986e-05]],\n",
       " \n",
       "         [[7.19513482e-05]],\n",
       " \n",
       "         [[2.03101135e-05]],\n",
       " \n",
       "         [[3.04611622e-05]],\n",
       " \n",
       "         [[5.58874526e-05]],\n",
       " \n",
       "         [[2.35180429e-04]],\n",
       " \n",
       "         [[1.30951867e-05]],\n",
       " \n",
       "         [[5.26354816e-05]],\n",
       " \n",
       "         [[6.85079503e-05]],\n",
       " \n",
       "         [[6.17807615e-04]],\n",
       " \n",
       "         [[1.83066673e-04]],\n",
       " \n",
       "         [[3.29770410e-05]],\n",
       " \n",
       "         [[3.99643183e-02]],\n",
       " \n",
       "         [[1.91483367e-03]],\n",
       " \n",
       "         [[5.75337399e-05]],\n",
       " \n",
       "         [[5.30794277e-05]],\n",
       " \n",
       "         [[6.33277814e-04]],\n",
       " \n",
       "         [[1.88163795e-05]],\n",
       " \n",
       "         [[1.76679605e-04]],\n",
       " \n",
       "         [[3.57827885e-05]],\n",
       " \n",
       "         [[2.74550146e-03]],\n",
       " \n",
       "         [[1.04503051e-04]],\n",
       " \n",
       "         [[5.55876002e-04]],\n",
       " \n",
       "         [[2.91383360e-04]],\n",
       " \n",
       "         [[2.94230646e-03]],\n",
       " \n",
       "         [[7.42678239e-05]],\n",
       " \n",
       "         [[3.07073060e-05]],\n",
       " \n",
       "         [[2.51638447e-03]],\n",
       " \n",
       "         [[1.49315601e-04]],\n",
       " \n",
       "         [[1.26066034e-05]],\n",
       " \n",
       "         [[2.30448804e-05]],\n",
       " \n",
       "         [[1.74209964e-03]],\n",
       " \n",
       "         [[1.43159350e-05]],\n",
       " \n",
       "         [[2.88819283e-04]],\n",
       " \n",
       "         [[3.19250347e-03]],\n",
       " \n",
       "         [[1.35454175e-04]],\n",
       " \n",
       "         [[5.50779332e-05]],\n",
       " \n",
       "         [[9.20622406e-05]],\n",
       " \n",
       "         [[1.58832734e-03]],\n",
       " \n",
       "         [[4.61378787e-03]],\n",
       " \n",
       "         [[4.95766173e-04]],\n",
       " \n",
       "         [[5.44704555e-04]],\n",
       " \n",
       "         [[2.83689988e-05]],\n",
       " \n",
       "         [[2.10267335e-05]],\n",
       " \n",
       "         [[1.88404066e-03]],\n",
       " \n",
       "         [[1.18967655e-04]],\n",
       " \n",
       "         [[1.45843342e-05]],\n",
       " \n",
       "         [[3.85321946e-05]],\n",
       " \n",
       "         [[1.08686087e-04]],\n",
       " \n",
       "         [[2.72994948e-04]],\n",
       " \n",
       "         [[9.05674679e-05]],\n",
       " \n",
       "         [[3.15391371e-05]],\n",
       " \n",
       "         [[8.27290933e-05]],\n",
       " \n",
       "         [[7.15539791e-05]],\n",
       " \n",
       "         [[6.12965319e-04]],\n",
       " \n",
       "         [[2.82286892e-05]],\n",
       " \n",
       "         [[5.92274871e-03]],\n",
       " \n",
       "         [[5.92175493e-05]],\n",
       " \n",
       "         [[1.65293695e-05]],\n",
       " \n",
       "         [[1.31283235e-03]],\n",
       " \n",
       "         [[7.12264664e-05]],\n",
       " \n",
       "         [[2.00326554e-04]],\n",
       " \n",
       "         [[4.79746331e-03]],\n",
       " \n",
       "         [[4.68677681e-05]],\n",
       " \n",
       "         [[1.52807534e-05]],\n",
       " \n",
       "         [[2.05833884e-03]],\n",
       " \n",
       "         [[3.56014680e-05]],\n",
       " \n",
       "         [[5.42029098e-04]],\n",
       " \n",
       "         [[1.72108848e-05]],\n",
       " \n",
       "         [[1.44403381e-03]],\n",
       " \n",
       "         [[9.02463871e-05]],\n",
       " \n",
       "         [[2.55261712e-05]],\n",
       " \n",
       "         [[4.27053856e-05]],\n",
       " \n",
       "         [[1.51418603e-03]],\n",
       " \n",
       "         [[4.70552841e-05]],\n",
       " \n",
       "         [[1.03031890e-03]],\n",
       " \n",
       "         [[2.39803398e-04]],\n",
       " \n",
       "         [[7.10990789e-05]],\n",
       " \n",
       "         [[1.94459746e-03]],\n",
       " \n",
       "         [[3.19778082e-05]],\n",
       " \n",
       "         [[1.38458505e-03]],\n",
       " \n",
       "         [[3.12080304e-03]],\n",
       " \n",
       "         [[1.19925023e-03]],\n",
       " \n",
       "         [[1.20416851e-04]],\n",
       " \n",
       "         [[4.56070935e-04]],\n",
       " \n",
       "         [[2.35657408e-05]],\n",
       " \n",
       "         [[3.52967018e-03]],\n",
       " \n",
       "         [[4.15885093e-04]],\n",
       " \n",
       "         [[1.14692864e-03]],\n",
       " \n",
       "         [[5.25935844e-04]],\n",
       " \n",
       "         [[4.06426057e-04]],\n",
       " \n",
       "         [[3.71461683e-05]],\n",
       " \n",
       "         [[2.80825800e-04]],\n",
       " \n",
       "         [[2.58190732e-04]],\n",
       " \n",
       "         [[1.33457006e-05]],\n",
       " \n",
       "         [[1.43378376e-04]],\n",
       " \n",
       "         [[3.18913771e-05]],\n",
       " \n",
       "         [[1.96734240e-04]],\n",
       " \n",
       "         [[3.67556536e-03]],\n",
       " \n",
       "         [[1.82623058e-04]],\n",
       " \n",
       "         [[3.39848804e-04]],\n",
       " \n",
       "         [[2.43418962e-02]],\n",
       " \n",
       "         [[1.02212827e-03]],\n",
       " \n",
       "         [[1.92039770e-05]],\n",
       " \n",
       "         [[1.02005270e-03]],\n",
       " \n",
       "         [[5.08442195e-03]],\n",
       " \n",
       "         [[5.51123485e-05]],\n",
       " \n",
       "         [[2.97599017e-05]],\n",
       " \n",
       "         [[2.59809871e-03]],\n",
       " \n",
       "         [[9.58643359e-05]],\n",
       " \n",
       "         [[1.68715208e-03]],\n",
       " \n",
       "         [[5.95681253e-04]],\n",
       " \n",
       "         [[7.59196628e-05]],\n",
       " \n",
       "         [[4.86249512e-04]],\n",
       " \n",
       "         [[7.00249046e-04]],\n",
       " \n",
       "         [[1.06686575e-03]],\n",
       " \n",
       "         [[1.33393005e-05]],\n",
       " \n",
       "         [[1.18447014e-03]],\n",
       " \n",
       "         [[1.09806540e-04]],\n",
       " \n",
       "         [[9.99395779e-05]],\n",
       " \n",
       "         [[5.31925834e-05]],\n",
       " \n",
       "         [[4.05663995e-05]],\n",
       " \n",
       "         [[1.37488942e-05]],\n",
       " \n",
       "         [[2.87298753e-04]],\n",
       " \n",
       "         [[1.57374248e-04]],\n",
       " \n",
       "         [[1.40780889e-04]],\n",
       " \n",
       "         [[2.81427167e-02]],\n",
       " \n",
       "         [[2.08014229e-04]],\n",
       " \n",
       "         [[5.50039986e-04]],\n",
       " \n",
       "         [[1.29299035e-04]],\n",
       " \n",
       "         [[1.99189526e-05]],\n",
       " \n",
       "         [[1.78701070e-03]],\n",
       " \n",
       "         [[4.49809385e-03]],\n",
       " \n",
       "         [[1.52480367e-04]],\n",
       " \n",
       "         [[3.97878794e-05]],\n",
       " \n",
       "         [[5.60149259e-04]],\n",
       " \n",
       "         [[4.65910452e-05]],\n",
       " \n",
       "         [[6.59193392e-05]],\n",
       " \n",
       "         [[7.19946256e-05]],\n",
       " \n",
       "         [[9.39156220e-04]],\n",
       " \n",
       "         [[4.40533076e-05]],\n",
       " \n",
       "         [[2.89089749e-05]],\n",
       " \n",
       "         [[4.05573664e-04]],\n",
       " \n",
       "         [[1.31769539e-05]],\n",
       " \n",
       "         [[4.44704201e-04]],\n",
       " \n",
       "         [[2.93713383e-04]],\n",
       " \n",
       "         [[1.03162602e-03]],\n",
       " \n",
       "         [[1.51173328e-04]],\n",
       " \n",
       "         [[1.71156740e-03]],\n",
       " \n",
       "         [[2.52359278e-05]],\n",
       " \n",
       "         [[1.21623023e-04]],\n",
       " \n",
       "         [[2.08088837e-04]],\n",
       " \n",
       "         [[4.17595838e-05]],\n",
       " \n",
       "         [[1.42607478e-05]],\n",
       " \n",
       "         [[1.83762063e-03]],\n",
       " \n",
       "         [[3.94371949e-04]],\n",
       " \n",
       "         [[4.60703578e-03]],\n",
       " \n",
       "         [[1.62567867e-05]],\n",
       " \n",
       "         [[1.47005012e-05]],\n",
       " \n",
       "         [[4.41704271e-03]],\n",
       " \n",
       "         [[9.36474316e-05]],\n",
       " \n",
       "         [[2.24994565e-05]],\n",
       " \n",
       "         [[5.14701474e-04]],\n",
       " \n",
       "         [[2.91002658e-03]],\n",
       " \n",
       "         [[3.92903201e-03]],\n",
       " \n",
       "         [[4.69381077e-04]],\n",
       " \n",
       "         [[6.52050294e-05]],\n",
       " \n",
       "         [[6.42830448e-04]],\n",
       " \n",
       "         [[1.19518612e-04]],\n",
       " \n",
       "         [[6.60086080e-05]],\n",
       " \n",
       "         [[2.19380629e-04]],\n",
       " \n",
       "         [[7.41001859e-05]],\n",
       " \n",
       "         [[1.90122537e-05]],\n",
       " \n",
       "         [[1.28083353e-04]],\n",
       " \n",
       "         [[5.54197526e-04]],\n",
       " \n",
       "         [[1.48488907e-04]],\n",
       " \n",
       "         [[3.00393847e-04]],\n",
       " \n",
       "         [[1.09389293e-04]],\n",
       " \n",
       "         [[2.16664467e-03]],\n",
       " \n",
       "         [[1.58949406e-05]],\n",
       " \n",
       "         [[7.45807658e-04]],\n",
       " \n",
       "         [[4.15419287e-04]],\n",
       " \n",
       "         [[1.40183303e-03]],\n",
       " \n",
       "         [[4.29229520e-04]],\n",
       " \n",
       "         [[4.58427443e-04]],\n",
       " \n",
       "         [[6.58085744e-04]],\n",
       " \n",
       "         [[5.57190680e-04]],\n",
       " \n",
       "         [[2.74445410e-05]],\n",
       " \n",
       "         [[4.40248368e-05]],\n",
       " \n",
       "         [[2.61943467e-04]],\n",
       " \n",
       "         [[3.38361366e-04]],\n",
       " \n",
       "         [[8.00571434e-05]],\n",
       " \n",
       "         [[2.90526514e-04]],\n",
       " \n",
       "         [[2.37134658e-03]],\n",
       " \n",
       "         [[2.50630523e-03]],\n",
       " \n",
       "         [[5.12378101e-05]],\n",
       " \n",
       "         [[4.32089297e-03]],\n",
       " \n",
       "         [[2.13547391e-05]],\n",
       " \n",
       "         [[3.89802130e-03]],\n",
       " \n",
       "         [[1.26066034e-05]],\n",
       " \n",
       "         [[1.14880875e-03]],\n",
       " \n",
       "         [[3.06319598e-05]],\n",
       " \n",
       "         [[1.58849091e-03]],\n",
       " \n",
       "         [[1.30136541e-05]],\n",
       " \n",
       "         [[2.24179402e-03]],\n",
       " \n",
       "         [[6.28847774e-05]],\n",
       " \n",
       "         [[5.78985346e-05]],\n",
       " \n",
       "         [[7.71743798e-05]],\n",
       " \n",
       "         [[3.23842032e-05]],\n",
       " \n",
       "         [[2.29195459e-03]],\n",
       " \n",
       "         [[7.72158673e-04]],\n",
       " \n",
       "         [[2.85230617e-05]],\n",
       " \n",
       "         [[1.39058020e-05]],\n",
       " \n",
       "         [[1.86250475e-03]],\n",
       " \n",
       "         [[4.05773862e-05]],\n",
       " \n",
       "         [[3.15507664e-03]],\n",
       " \n",
       "         [[4.49567269e-05]],\n",
       " \n",
       "         [[6.10304305e-05]],\n",
       " \n",
       "         [[3.47538356e-04]],\n",
       " \n",
       "         [[1.07192923e-03]],\n",
       " \n",
       "         [[5.35315121e-05]],\n",
       " \n",
       "         [[1.06748492e-04]],\n",
       " \n",
       "         [[1.91538056e-04]],\n",
       " \n",
       "         [[4.82337127e-05]],\n",
       " \n",
       "         [[2.62975573e-05]],\n",
       " \n",
       "         [[4.02272446e-04]],\n",
       " \n",
       "         [[1.61550066e-03]],\n",
       " \n",
       "         [[9.32419614e-04]],\n",
       " \n",
       "         [[3.99362762e-04]],\n",
       " \n",
       "         [[1.94627748e-04]],\n",
       " \n",
       "         [[2.45612755e-05]],\n",
       " \n",
       "         [[2.63027381e-03]],\n",
       " \n",
       "         [[1.92732841e-04]],\n",
       " \n",
       "         [[3.88497792e-05]],\n",
       " \n",
       "         [[5.83721740e-05]],\n",
       " \n",
       "         [[1.75922259e-03]],\n",
       " \n",
       "         [[1.04595827e-04]],\n",
       " \n",
       "         [[9.07102227e-03]],\n",
       " \n",
       "         [[8.06461030e-05]],\n",
       " \n",
       "         [[1.26092127e-05]],\n",
       " \n",
       "         [[3.10854230e-05]],\n",
       " \n",
       "         [[1.14236289e-04]],\n",
       " \n",
       "         [[2.88417004e-03]],\n",
       " \n",
       "         [[8.56670842e-04]],\n",
       " \n",
       "         [[9.73855422e-05]],\n",
       " \n",
       "         [[3.33407137e-04]],\n",
       " \n",
       "         [[2.30598846e-04]],\n",
       " \n",
       "         [[1.77273032e-05]],\n",
       " \n",
       "         [[1.58704024e-05]],\n",
       " \n",
       "         [[1.51504914e-03]],\n",
       " \n",
       "         [[3.68909277e-05]],\n",
       " \n",
       "         [[6.21863641e-03]],\n",
       " \n",
       "         [[1.84599194e-04]],\n",
       " \n",
       "         [[1.43334968e-04]],\n",
       " \n",
       "         [[1.12038781e-03]],\n",
       " \n",
       "         [[3.75118281e-04]],\n",
       " \n",
       "         [[1.38274685e-04]],\n",
       " \n",
       "         [[2.77609390e-04]],\n",
       " \n",
       "         [[1.28719502e-03]],\n",
       " \n",
       "         [[4.28457533e-05]],\n",
       " \n",
       "         [[8.74616235e-05]],\n",
       " \n",
       "         [[4.54712208e-05]],\n",
       " \n",
       "         [[3.50049377e-04]],\n",
       " \n",
       "         [[7.80674454e-05]],\n",
       " \n",
       "         [[1.01651496e-03]],\n",
       " \n",
       "         [[5.31060155e-03]],\n",
       " \n",
       "         [[1.78515236e-03]],\n",
       " \n",
       "         [[9.28535519e-05]],\n",
       " \n",
       "         [[5.58150386e-05]],\n",
       " \n",
       "         [[2.52466398e-05]],\n",
       " \n",
       "         [[1.32326395e-05]],\n",
       " \n",
       "         [[1.95545051e-03]],\n",
       " \n",
       "         [[1.87556998e-05]],\n",
       " \n",
       "         [[1.11564144e-03]],\n",
       " \n",
       "         [[6.98443269e-04]],\n",
       " \n",
       "         [[3.06630573e-05]],\n",
       " \n",
       "         [[4.22284065e-04]],\n",
       " \n",
       "         [[4.15543705e-04]],\n",
       " \n",
       "         [[1.21800906e-04]],\n",
       " \n",
       "         [[2.15119042e-04]],\n",
       " \n",
       "         [[8.83063651e-04]],\n",
       " \n",
       "         [[3.28911236e-04]],\n",
       " \n",
       "         [[3.50721530e-05]],\n",
       " \n",
       "         [[6.02155160e-05]],\n",
       " \n",
       "         [[4.23829515e-05]],\n",
       " \n",
       "         [[1.85068508e-04]],\n",
       " \n",
       "         [[1.90767387e-04]],\n",
       " \n",
       "         [[1.84576129e-04]],\n",
       " \n",
       "         [[3.05141966e-05]],\n",
       " \n",
       "         [[5.92533033e-05]],\n",
       " \n",
       "         [[4.97451001e-05]],\n",
       " \n",
       "         [[1.43446829e-04]],\n",
       " \n",
       "         [[9.13459735e-05]],\n",
       " \n",
       "         [[1.81822979e-04]],\n",
       " \n",
       "         [[4.78608208e-03]],\n",
       " \n",
       "         [[1.81367167e-03]],\n",
       " \n",
       "         [[1.38764663e-04]],\n",
       " \n",
       "         [[2.11374648e-03]],\n",
       " \n",
       "         [[2.09075770e-05]],\n",
       " \n",
       "         [[1.49898278e-05]],\n",
       " \n",
       "         [[5.70156127e-02]],\n",
       " \n",
       "         [[8.32051388e-04]],\n",
       " \n",
       "         [[1.32785162e-05]],\n",
       " \n",
       "         [[1.46311580e-03]],\n",
       " \n",
       "         [[1.90696097e-04]],\n",
       " \n",
       "         [[9.92983914e-05]],\n",
       " \n",
       "         [[9.57925949e-05]],\n",
       " \n",
       "         [[5.84622867e-05]],\n",
       " \n",
       "         [[1.47705420e-03]],\n",
       " \n",
       "         [[5.31299971e-04]],\n",
       " \n",
       "         [[1.82572228e-03]],\n",
       " \n",
       "         [[4.80695890e-05]],\n",
       " \n",
       "         [[3.51025374e-05]],\n",
       " \n",
       "         [[4.98765185e-05]],\n",
       " \n",
       "         [[9.13951662e-05]],\n",
       " \n",
       "         [[9.67078449e-05]],\n",
       " \n",
       "         [[4.41952259e-04]],\n",
       " \n",
       "         [[6.86722342e-05]],\n",
       " \n",
       "         [[1.05222128e-03]],\n",
       " \n",
       "         [[5.30119229e-04]],\n",
       " \n",
       "         [[6.36688346e-05]],\n",
       " \n",
       "         [[9.14183166e-03]],\n",
       " \n",
       "         [[3.13460419e-04]],\n",
       " \n",
       "         [[1.54180088e-04]],\n",
       " \n",
       "         [[6.30490758e-05]],\n",
       " \n",
       "         [[2.30637350e-04]],\n",
       " \n",
       "         [[8.97164980e-04]],\n",
       " \n",
       "         [[3.33862961e-03]],\n",
       " \n",
       "         [[2.81977747e-03]],\n",
       " \n",
       "         [[3.82818471e-05]],\n",
       " \n",
       "         [[1.17314055e-04]],\n",
       " \n",
       "         [[3.14027275e-05]],\n",
       " \n",
       "         [[2.65969138e-05]],\n",
       " \n",
       "         [[4.02997201e-03]],\n",
       " \n",
       "         [[2.01447983e-03]],\n",
       " \n",
       "         [[1.03431783e-04]],\n",
       " \n",
       "         [[1.49412677e-02]],\n",
       " \n",
       "         [[4.95133980e-04]],\n",
       " \n",
       "         [[1.45331296e-05]],\n",
       " \n",
       "         [[1.03930870e-04]],\n",
       " \n",
       "         [[7.75695516e-05]],\n",
       " \n",
       "         [[7.77224268e-05]],\n",
       " \n",
       "         [[2.64709979e-05]],\n",
       " \n",
       "         [[7.00608711e-04]],\n",
       " \n",
       "         [[1.94781867e-03]],\n",
       " \n",
       "         [[9.17600992e-05]],\n",
       " \n",
       "         [[4.62922872e-05]],\n",
       " \n",
       "         [[1.26066034e-05]],\n",
       " \n",
       "         [[1.92314954e-04]],\n",
       " \n",
       "         [[2.74601858e-04]],\n",
       " \n",
       "         [[2.34945364e-05]],\n",
       " \n",
       "         [[2.37418615e-04]],\n",
       " \n",
       "         [[6.02276887e-05]],\n",
       " \n",
       "         [[4.81416442e-04]],\n",
       " \n",
       "         [[1.26891988e-04]],\n",
       " \n",
       "         [[2.36894819e-03]],\n",
       " \n",
       "         [[1.76338071e-05]],\n",
       " \n",
       "         [[1.46382255e-04]],\n",
       " \n",
       "         [[1.82166463e-04]],\n",
       " \n",
       "         [[3.04129771e-05]],\n",
       " \n",
       "         [[9.82109123e-05]],\n",
       " \n",
       "         [[3.26168211e-03]],\n",
       " \n",
       "         [[1.35474329e-04]],\n",
       " \n",
       "         [[4.94404056e-04]],\n",
       " \n",
       "         [[2.84300069e-04]],\n",
       " \n",
       "         [[1.96059205e-04]],\n",
       " \n",
       "         [[2.85791932e-04]],\n",
       " \n",
       "         [[6.40931586e-03]],\n",
       " \n",
       "         [[5.70189513e-05]],\n",
       " \n",
       "         [[1.75404675e-05]],\n",
       " \n",
       "         [[9.02140746e-04]],\n",
       " \n",
       "         [[1.62559270e-04]],\n",
       " \n",
       "         [[6.05471141e-05]],\n",
       " \n",
       "         [[4.01516409e-05]],\n",
       " \n",
       "         [[7.36158749e-04]],\n",
       " \n",
       "         [[1.90762119e-04]],\n",
       " \n",
       "         [[1.88356003e-04]],\n",
       " \n",
       "         [[2.33650862e-04]],\n",
       " \n",
       "         [[5.78647247e-04]],\n",
       " \n",
       "         [[7.75544613e-05]],\n",
       " \n",
       "         [[1.40566984e-03]],\n",
       " \n",
       "         [[8.74189718e-05]],\n",
       " \n",
       "         [[5.62739675e-04]],\n",
       " \n",
       "         [[1.87211830e-04]],\n",
       " \n",
       "         [[3.82606609e-04]],\n",
       " \n",
       "         [[4.07173648e-04]],\n",
       " \n",
       "         [[1.31529747e-02]],\n",
       " \n",
       "         [[1.13367513e-02]],\n",
       " \n",
       "         [[5.39599801e-04]],\n",
       " \n",
       "         [[1.24827353e-03]],\n",
       " \n",
       "         [[6.46954402e-02]],\n",
       " \n",
       "         [[1.00923309e-04]],\n",
       " \n",
       "         [[4.23925929e-04]],\n",
       " \n",
       "         [[1.30153800e-04]],\n",
       " \n",
       "         [[2.61554815e-04]],\n",
       " \n",
       "         [[2.28030360e-04]],\n",
       " \n",
       "         [[2.25902968e-05]],\n",
       " \n",
       "         [[1.46086051e-04]],\n",
       " \n",
       "         [[9.91419889e-04]],\n",
       " \n",
       "         [[2.43355553e-05]],\n",
       " \n",
       "         [[8.14587693e-05]],\n",
       " \n",
       "         [[2.19478784e-03]],\n",
       " \n",
       "         [[2.57696817e-03]],\n",
       " \n",
       "         [[1.24652055e-04]],\n",
       " \n",
       "         [[1.30962799e-04]],\n",
       " \n",
       "         [[2.31535723e-05]],\n",
       " \n",
       "         [[3.47005662e-05]],\n",
       " \n",
       "         [[2.16600420e-05]],\n",
       " \n",
       "         [[1.77804159e-05]],\n",
       " \n",
       "         [[1.56180522e-05]],\n",
       " \n",
       "         [[1.86864800e-05]],\n",
       " \n",
       "         [[5.62410045e-04]],\n",
       " \n",
       "         [[1.78152623e-05]],\n",
       " \n",
       "         [[2.08600177e-05]],\n",
       " \n",
       "         [[6.42542363e-05]],\n",
       " \n",
       "         [[1.75449513e-05]],\n",
       " \n",
       "         [[2.04765165e-05]],\n",
       " \n",
       "         [[6.76155323e-05]],\n",
       " \n",
       "         [[4.98389563e-05]],\n",
       " \n",
       "         [[4.23459249e-04]],\n",
       " \n",
       "         [[1.19619421e-03]],\n",
       " \n",
       "         [[1.93791784e-05]],\n",
       " \n",
       "         [[9.89832115e-05]],\n",
       " \n",
       "         [[5.18753659e-05]],\n",
       " \n",
       "         [[1.73653025e-05]],\n",
       " \n",
       "         [[2.76165902e-05]],\n",
       " \n",
       "         [[2.72573907e-05]],\n",
       " \n",
       "         [[1.20107412e-04]],\n",
       " \n",
       "         [[1.27547944e-03]],\n",
       " \n",
       "         [[7.66623270e-05]],\n",
       " \n",
       "         [[1.16640190e-03]],\n",
       " \n",
       "         [[2.57504667e-04]],\n",
       " \n",
       "         [[1.36571121e-03]],\n",
       " \n",
       "         [[1.57924904e-03]],\n",
       " \n",
       "         [[1.79986047e-04]],\n",
       " \n",
       "         [[1.74568864e-04]],\n",
       " \n",
       "         [[7.39478157e-04]],\n",
       " \n",
       "         [[2.49433251e-05]],\n",
       " \n",
       "         [[1.78905848e-05]],\n",
       " \n",
       "         [[4.74923290e-04]],\n",
       " \n",
       "         [[1.70839461e-03]],\n",
       " \n",
       "         [[1.88734593e-05]],\n",
       " \n",
       "         [[2.06324712e-05]],\n",
       " \n",
       "         [[5.98004699e-05]],\n",
       " \n",
       "         [[1.74354300e-05]],\n",
       " \n",
       "         [[7.86518285e-05]],\n",
       " \n",
       "         [[8.15591193e-05]],\n",
       " \n",
       "         [[1.31796560e-05]],\n",
       " \n",
       "         [[7.21922901e-04]],\n",
       " \n",
       "         [[2.97645427e-04]],\n",
       " \n",
       "         [[1.66730932e-03]],\n",
       " \n",
       "         [[3.10120085e-04]],\n",
       " \n",
       "         [[1.54326542e-03]],\n",
       " \n",
       "         [[5.74975181e-03]],\n",
       " \n",
       "         [[6.79655524e-04]],\n",
       " \n",
       "         [[1.74708184e-04]],\n",
       " \n",
       "         [[1.95016887e-03]],\n",
       " \n",
       "         [[2.07489403e-03]],\n",
       " \n",
       "         [[6.93374139e-04]],\n",
       " \n",
       "         [[2.06241297e-04]],\n",
       " \n",
       "         [[7.38618989e-03]],\n",
       " \n",
       "         [[5.22590766e-04]],\n",
       " \n",
       "         [[1.95955578e-02]],\n",
       " \n",
       "         [[4.62334974e-05]],\n",
       " \n",
       "         [[2.13070351e-04]],\n",
       " \n",
       "         [[2.75917264e-04]],\n",
       " \n",
       "         [[1.02209032e-03]],\n",
       " \n",
       "         [[1.29749731e-03]],\n",
       " \n",
       "         [[1.35221329e-04]],\n",
       " \n",
       "         [[3.45263863e-04]],\n",
       " \n",
       "         [[5.73295583e-05]],\n",
       " \n",
       "         [[1.23322010e-04]],\n",
       " \n",
       "         [[8.82848472e-05]],\n",
       " \n",
       "         [[3.72342001e-05]],\n",
       " \n",
       "         [[9.03810069e-05]],\n",
       " \n",
       "         [[1.28125312e-05]],\n",
       " \n",
       "         [[6.20637147e-05]],\n",
       " \n",
       "         [[7.37922237e-05]],\n",
       " \n",
       "         [[1.27097446e-05]],\n",
       " \n",
       "         [[1.75889618e-05]],\n",
       " \n",
       "         [[3.08349467e-04]],\n",
       " \n",
       "         [[1.05080241e-03]]]], dtype=float32)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openvino import inference_engine as ie\n",
    "\n",
    "# Create an instance of the OpenVINO Inference Engine Core \n",
    "# This is the key module of the OpenVINO Inference Engine\n",
    "ie_core = ie.IECore()\n",
    "\n",
    "# Read a network from the Intermediate Representation (IR)\n",
    "network = ie.IENetwork(os.path.join(WORKSHOP_DATA_PATH, 'model.xml'), \n",
    "                       os.path.join(WORKSHOP_DATA_PATH, 'model.bin'))\n",
    "\n",
    "# Find inputs of the model\n",
    "input_layer = next(iter(network.inputs))\n",
    "\n",
    "# Get input shape of the network\n",
    "input_shape = network.inputs[input_layer].shape\n",
    "\n",
    "# Load the network that was read from the Intermediate Representation (IR) \n",
    "# to the CPU device \n",
    "network_loaded_on_device = ie_core.load_network(network=network, device_name='CPU')\n",
    "\n",
    "# Start an inference of the loaded network and return output data\n",
    "network_loaded_on_device.infer(inputs={input_layer: np.random.rand(*input_shape)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information, go to references of [OpenVINO Inference Engine Python API](https://docs.openvinotoolkit.org/latest/ie_python_api/annotated.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./pictures/infer.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: What is SSD MobileNet V2?<a id='s2'></a>\n",
    "\n",
    "![](pictures/mobileNet-SSD-network-architecture.png)\n",
    "\n",
    "The `ssd_mobilenet_v2_coco` model is a [Single-Shot multibox Detection (SSD)](https://arxiv.org/pdf/1801.04381.pdf) network for object detection. The model has been trained from the Common Objects in Context (COCO) image dataset.\n",
    "\n",
    "The model input is a blob that consists of a single image of `1x3x300x300` in the `RGB` order.\n",
    "\n",
    "The model output is a typical vector containing the tracked object data. Note that the `class_id` data is now significant and should be used to determine the classification for any detected object.\n",
    "\n",
    "Model outputs:\n",
    "\n",
    "1. Classifier, name - `detection_classes`, contains predicted bounding boxes classes in range `[1, 91]`. The model was trained on Microsoft\\* COCO dataset version with 90 categories of objects.\n",
    "2. Probability, name - `detection_scores`, contains probability of detected bounding boxes.\n",
    "3. Detection box, name - `detection_boxes`, contains detection boxes coordinates in format `[y_min, x_min, y_max, x_max]`, where (`x_min`, `y_min`)  are coordinates top left corner, (`x_max`, `y_max`) are coordinates of the right bottom corner. Coordinates are rescaled to the input image size.\n",
    "4. Detections number, name - `num_detections`, contains the number of predicted detection boxes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Where Can I Find the Model?<a id='s3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the OpenVINO™ toolkit, you can easily download models from the [Intel&reg; Open Model Zoo](https://github.com/opencv/open_model_zoo).\n",
    "\n",
    "\n",
    "To see all available models (both public open-sourse from different frameworks (TensorFlow\\*, Caffe\\*, MxNet\\*, PyTorch\\* and others) and Intel&reg; ones), run the `downloader.py` script with the `--print_all` parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ${INTEL_OPENVINO_DIR}/deployment_tools/open_model_zoo/tools/downloader/downloader.py --print_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to download an object-detection model called `ssd_mobilenet_v2_coco` using the [Model Downloader](https://github.com/opencv/open_model_zoo/tree/master/tools/downloader)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ${INTEL_OPENVINO_DIR}/deployment_tools/open_model_zoo/tools/downloader/downloader.py \\\n",
    "--name ssd_mobilenet_v2_coco \\\n",
    "--output_dir ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the Model Downloader can load not only publicly famous model, but also various models created at Intel for a range of tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pictures/models.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Downloader downloaded the model to the following directory: `data/public/ssd_mobilenet_v2_coco/ssd_mobilenet_v2_coco_2018_03_29`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/public/ssd_mobilenet_v2_coco/ssd_mobilenet_v2_coco_2018_03_29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Infer SSD MobileNet V2 on TensorFlow<a id='s4'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.gfile import GFile\n",
    "\n",
    "# Path to the TensorFlow model\n",
    "model = os.path.join('data', \n",
    "                     'public', 'ssd_mobilenet_v2_coco', \n",
    "                     'ssd_mobilenet_v2_coco_2018_03_29', \n",
    "                     'frozen_inference_graph.pb')\n",
    "\n",
    "# SSD mobilenet v2 contains following output nodes\n",
    "output_names = ['detection_classes:0','detection_scores:0', 'detection_boxes:0', 'num_detections:0']\n",
    "\n",
    "# Create a graph\n",
    "graph = tf.Graph()\n",
    "\n",
    "# Create graph definitions\n",
    "graph_def = tf.GraphDef()\n",
    "\n",
    "# Read model to the graph definitions\n",
    "with open(model, \"rb\") as model_file:\n",
    "    graph_def.ParseFromString(model_file.read())\n",
    "\n",
    "\n",
    "with graph.as_default():\n",
    "    # Import the graph definitions to TensorFlow\n",
    "    tf.import_graph_def(graph_def, name='')\n",
    "    # Get tensors for output nodes\n",
    "    output_tensors = [graph.get_tensor_by_name(layer_name) for layer_name in output_names] \n",
    "\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        # Inference the model for random datates\n",
    "        print(session.run(output_tensors, feed_dict = {'image_tensor:0' : np.random.rand(1, 300, 300, 3)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pictures/inference_tf.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5: Infer on Real Data on TensorFlow<a id='s5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the TensorFlow `ssd_mobilenet_v2_coco` model, we need some utility functions and constant values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging as log\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Initialize logging\n",
    "log.basicConfig(format=\"[ %(levelname)s ] %(message)s\", level=log.INFO, stream=sys.stdout)\n",
    "\n",
    "# Define how many times we run inference to get better performance\n",
    "NUM_RUNS = 1 \n",
    "# Number of images for one inference\n",
    "BATCH = 1\n",
    "\n",
    "# Contains all data for the workshop\n",
    "WORKSHOP_DATA_PATH = os.path.join('.', 'data')\n",
    "\n",
    "# Path to a test image\n",
    "IMAGE = os.path.join(WORKSHOP_DATA_PATH, 'images', 'input', 'cats.jpg')\n",
    "\n",
    "# Path to the downloaded TensorFlow image\n",
    "SSD_ASSETS = os.path.join(WORKSHOP_DATA_PATH, 'public', 'ssd_mobilenet_v2_coco')\n",
    "\n",
    "# Path to the downloaded frozen TensorFlow image\n",
    "TF_MODEL = os.path.join(SSD_ASSETS, 'ssd_mobilenet_v2_coco_2018_03_29', 'frozen_inference_graph.pb')\n",
    "\n",
    "# Path to the resulting TensorFlow image\n",
    "TF_RESULT_IMAGE = os.path.join(WORKSHOP_DATA_PATH, 'images', 'output', 'tensorflow_output.png')\n",
    "\n",
    "# Path to the Inference Engine FP32 model\n",
    "IE_MODEL_FP32_XML = os.path.join(SSD_ASSETS, 'FP32', 'ssd_mobilenet_v2_coco.xml')\n",
    "IE_MODEL_FP32_BIN = os.path.join(SSD_ASSETS, 'FP32', 'ssd_mobilenet_v2_coco.bin')\n",
    "\n",
    "# Path to the Inference Engine INT8 model optimized with the Default algorithm\n",
    "IE_MODEL_DEFAULT_INT8_XML = os.path.join(SSD_ASSETS, 'INT8', 'default', 'optimized', 'ssd_mobilenet_v2_coco.xml')\n",
    "IE_MODEL_DEFAULT_INT8_BIN = os.path.join(SSD_ASSETS, 'INT8', 'default', 'optimized', 'ssd_mobilenet_v2_coco.bin')\n",
    "\n",
    "# Path to the Inference Engine INT8 model optimized  with the AccuracyAware algorithm\n",
    "IE_MODEL_AA_INT8_XML = os.path.join(SSD_ASSETS, 'INT8', 'acuracy_aware', 'optimized', 'ssd_mobilenet_v2_coco.xml')\n",
    "IE_MODEL_AA_INT8_BIN = os.path.join(SSD_ASSETS, 'INT8', 'acuracy_aware', 'optimized', 'ssd_mobilenet_v2_coco.bin')\n",
    "\n",
    "# Path to the resulting TensorFlow image\n",
    "IE_RESULT_IMAGE = os.path.join(WORKSHOP_DATA_PATH, 'images', 'output', 'inference_engine_output.png')\n",
    "\n",
    "# Path to the combination of the resulting TensorFlow and Inference Engine images\n",
    "COMBO_RESULT_IMAGE = os.path.join(WORKSHOP_DATA_PATH, 'images', 'output', 'combo_output.png')\n",
    "\n",
    "PERFORMANCE = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OpenCV for image processing\n",
    "import cv2\n",
    "\n",
    "def read_resize_image(path_to_image: str, width: int, height: int):\n",
    "    \"\"\"\n",
    "    Takes an image and resizes it to the given dimensions.\n",
    "    \"\"\"\n",
    "    # Load the image \n",
    "    raw_image = cv2.imread(path_to_image)\n",
    "    # Return the image resized to the (width, height) format\n",
    "    return cv2.resize(raw_image, (width, height), interpolation=cv2.INTER_NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required functions from TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "\n",
    "def tf_inference(graph: tf.Graph, input_data, input_name: str, outputs_names: list) -> tuple:\n",
    "    \"\"\"\n",
    "    Returns TensorFlow model inference results.\n",
    "    \"\"\"\n",
    "    \n",
    "    log.info(\"Running inference with TensorFlow ...\")\n",
    "  \n",
    "    # Get the input tensor by name\n",
    "    input_tensor =  graph.get_tensor_by_name('{}:0'.format(input_name))\n",
    "    \n",
    "    # Fill input data\n",
    "    feed_dict = {\n",
    "        input_tensor: [input_data, ] \n",
    "    }\n",
    "\n",
    "    # Collect output tensors\n",
    "    output_tensors = []\n",
    "    \n",
    "    for output_name in outputs_names:\n",
    "        tensor = graph.get_tensor_by_name('{}:0'.format(output_name))\n",
    "        output_tensors.append(tensor)\n",
    "    \n",
    "    # Run inference and get performance\n",
    "    log.info(\"Running tf.Session\")\n",
    "    with graph.as_default():\n",
    "        with tf.Session(graph=graph) as session:\n",
    "            inference_start = time.time()\n",
    "            outputs = session.run(output_tensors, feed_dict=feed_dict)\n",
    "            inference_end = time.time()\n",
    "    \n",
    "    # Collect inference results\n",
    "    res = dict(zip(outputs_names, outputs))\n",
    "    \n",
    "    log.info(\"TensorFlow reference collected successfully\")\n",
    "    \n",
    "    return res, inference_end - inference_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def tf_main(path_to_pb_model: str, \n",
    "            path_to_original_image: str, \n",
    "            number_inference: int = 1):\n",
    "    \"\"\"\n",
    "    Entrypoint to infer with TensorFlow.\n",
    "    \"\"\"\n",
    "    log.info('COMMON: image preprocessing')\n",
    "    \n",
    "    # Size of the image is 300x300 pixels, 3 channels in the RGB format\n",
    "    width = 300\n",
    "    \n",
    "    image_shape = (300, 300, 3)\n",
    "    \n",
    "    resized_image = read_resize_image(path_to_original_image, width, width)\n",
    "    \n",
    "    reshaped_image = np.reshape(resized_image, image_shape)\n",
    "    \n",
    "    log.info('Current shape: {}'.format(reshaped_image.shape))\n",
    "\n",
    "    log.info('TENSORFLOW SPECIFIC: Loading a model with TensorFlow')\n",
    "    \n",
    "    graph = tf.Graph()\n",
    "    \n",
    "    graph_def = tf.GraphDef()\n",
    "\n",
    "    with open(path_to_pb_model, \"rb\") as model_file:\n",
    "        graph_def.ParseFromString(model_file.read())\n",
    "\n",
    "    with graph.as_default():\n",
    "        tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "    log.info(\"TensorFlow graph was created\")\n",
    "    \n",
    "    # We use SSD MobileNet V2 and we know the name of the input \n",
    "    input_layer = 'image_tensor'\n",
    "    \n",
    "    # And we know names of outputs\n",
    "    output_layers = ['num_detections', 'detection_classes', 'detection_scores', 'detection_boxes']\n",
    "    \n",
    "    collected_inference_time = []\n",
    "    \n",
    "    for run in range(number_inference):\n",
    "        raw_results, inference_time = tf_inference(graph, reshaped_image, input_layer, output_layers)\n",
    "        collected_inference_time.append(inference_time)\n",
    "    \n",
    "    tensorflow_average_inference_time = sum(collected_inference_time) / number_inference\n",
    "    \n",
    "    log.info('TENSORFLOW SPECIFIC: Plain inference finished')\n",
    "\n",
    "    return raw_results, tensorflow_average_inference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Image class from display to show an image\n",
    "from IPython.display import Image\n",
    "# Show the image in the notebok\n",
    "Image(filename=IMAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer the Model on the Real Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "framework = 'TF'\n",
    "device = 'CPU'\n",
    "name = '{f} on {d}'.format(f=framework, d=device)\n",
    "\n",
    "tensorflow_fps_collected = []\n",
    "\n",
    "# Run inference on TensorFlow\n",
    "tensorflow_predictions, tensorflow_average_inference_time = tf_main(TF_MODEL, IMAGE, number_inference=NUM_RUNS)\n",
    "    \n",
    "log.info('Inference Time of SSD MobileNet V2 {} is {} seconds'.format(name, tensorflow_average_inference_time))\n",
    "\n",
    "# Calculate FPS from inference time\n",
    "tensorflow_average_fps = 1 / tensorflow_average_inference_time\n",
    "\n",
    "log.info('{} frame per seconds (FPS): {}'.format(name, tensorflow_average_fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tensorflow_predictions['num_detections']) # get number of detected objects\n",
    "print(tensorflow_predictions['detection_classes'][0])# get predicted classes IDs\n",
    "print(tensorflow_predictions['detection_scores'][0]) # get probabilities for predicted classes\n",
    "print(tensorflow_predictions['detection_boxes'][0]) # get boxes for predicted objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import utility functions to process images from TensorFlow and draw images\n",
    "from utils import parse_od_output, draw_image\n",
    "\n",
    "# Import the Image class from display to show an image\n",
    "from IPython.display import Image\n",
    "\n",
    "processd_tensorflow_predictions = parse_od_output(tensorflow_predictions)\n",
    "draw_image(IMAGE, processd_tensorflow_predictions, TF_RESULT_IMAGE)\n",
    "\n",
    "# Show the image in the notebok\n",
    "Image(filename=TF_RESULT_IMAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 6: [OpenVINO&trade;](https://docs.openvinotoolkit.org/) Overview<a id='s6'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino import inference_engine as ie\n",
    "\n",
    "# Create an instance of the OpenVINO Inference Engine Core \n",
    "# This is the key module of the OpenVINO Inference Engine\n",
    "ie_core = ie.IECore()\n",
    "\n",
    "# Read a network from the Intermediate Representation (IR)\n",
    "network = ie.IENetwork(os.path.join(WORKSHOP_DATA_PATH, 'model.xml'), \n",
    "                       os.path.join(WORKSHOP_DATA_PATH, 'model.bin'))\n",
    "\n",
    "# Find inputs of the model\n",
    "input_layer = next(iter(network.inputs))\n",
    "\n",
    "# Get input shape of the network\n",
    "input_shape = network.inputs[input_layer].shape\n",
    "\n",
    "# Load the network that was read from the Intermediate Representation (IR) \n",
    "# to the CPU device \n",
    "network_loaded_on_device = ie_core.load_network(network=network, device_name='CPU')\n",
    "\n",
    "# Start an inference of the loaded network and return output data\n",
    "network_loaded_on_device.infer(inputs={input_layer: np.random.rand(*input_shape)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./pictures/infer.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pictures/openvino_toolkit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pictures/additional_tools.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 7: [Model Optimizer](https://docs.openvinotoolkit.org/latest/_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html) - Entry to OpenVINO&trade;<a id='s7'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pictures/model_optimizer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let's convert the TensorFlow model to the IR format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ${INTEL_OPENVINO_DIR}/deployment_tools/model_optimizer/mo.py \\\n",
    "--output_dir=data/public/ssd_mobilenet_v2_coco/FP32 \\\n",
    "--reverse_input_channels \\\n",
    "--model_name=ssd_mobilenet_v2_coco \\\n",
    "--transformations_config=${INTEL_OPENVINO_DIR}/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json \\\n",
    "--tensorflow_object_detection_api_pipeline_config=data/public/ssd_mobilenet_v2_coco/ssd_mobilenet_v2_coco_2018_03_29/pipeline.config \\\n",
    "--output=detection_classes,detection_scores,detection_boxes,num_detections \\\n",
    "--input_model=data/public/ssd_mobilenet_v2_coco/ssd_mobilenet_v2_coco_2018_03_29/frozen_inference_graph.pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./pictures/openvino_support.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the Intermediate Representation of the SSD MobileNet V2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat data/public/ssd_mobilenet_v2_coco/FP32/ssd_mobilenet_v2_coco.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 8: Inference of SSD MobileNet V2 on [OpenVINO™ Inference Engine](https://docs.openvinotoolkit.org/latest/_docs_IE_DG_Deep_Learning_Inference_Engine_DevGuide.html)<a id='s8'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.inference_engine import IECore, IENetwork\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def ie_inference(path_to_model_xml: str, path_to_model_bin: str, path_to_original_image: str, device='CPU', batch=1):\n",
    "    \"\"\"\n",
    "    Entrypoint to infer with the OpenVINO Inference Engine\n",
    "    \"\"\"\n",
    "\n",
    "    # Now let's create the IECore() entity \n",
    "    log.info(\"Creating Inference Engine Core\")   \n",
    "    ie = IECore()\n",
    "\n",
    "    # First, create a network (Note: you need to provide model in the IR previously converted with Model Optimizer)\n",
    "    log.info(\"Reading IR...\")\n",
    "    net = IENetwork(model=path_to_model_xml, weights=path_to_model_bin)\n",
    "\n",
    "    # Get input and output blob of the network\n",
    "    input_blob = next(iter(net.inputs))\n",
    "    out_blob = next(iter(net.outputs))\n",
    "\n",
    "    # Reshape the network to the needed batch\n",
    "    n, c, h, w = net.inputs[input_blob].shape\n",
    "    \n",
    "    net.reshape({input_blob: (batch, c, h, w)})\n",
    "    \n",
    "    n, c, h, w = net.inputs[input_blob].shape\n",
    "    \n",
    "    # Resize the image \n",
    "    log.info('COMMON: image preprocessing')\n",
    "    image = read_resize_image(path_to_original_image, h, w)\n",
    "    \n",
    "    # Now we load Network to the plugin\n",
    "    log.info(\"Loading IR to the plugin...\")\n",
    "    exec_net = ie.load_network(network=net, device_name=device, num_requests=2)\n",
    "\n",
    "    del net\n",
    "\n",
    "    labels_map = None\n",
    "    \n",
    "    # Read and preprocess the input image\n",
    "    image = image[..., ::-1]\n",
    "    in_frame = image.transpose((2, 0, 1))  # Change data layout from HWC to CHW\n",
    "    batched_frame = np.array([in_frame for _ in range(batch)])\n",
    "    log.info('Current shape: {}'.format(batched_frame.shape))\n",
    "\n",
    "    # Now we run an inference on the target device\n",
    "    inference_start = time.time()\n",
    "    res = exec_net.infer(inputs={input_blob: batched_frame})\n",
    "    inference_end = time.time()\n",
    "\n",
    "    log.info('INFERENCE ENGINE SPECIFIC: no post-processing')\n",
    "\n",
    "    return res[out_blob], inference_end - inference_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ie_main(xml:str, bin:str, device:str, postfix: str = ''):\n",
    "    name = '{f} {p} on {d}'.format(f='IE', p=postfix, d=device)\n",
    "\n",
    "    inference_engine_fps_collected = []\n",
    "\n",
    "    for i in range(NUM_RUNS):\n",
    "        # Run an inference on OpenVINO Inference Engine\n",
    "        predictions, inference_time = ie_inference(xml, bin,\n",
    "                                                   IMAGE,\n",
    "                                                   device,\n",
    "                                                   batch=BATCH)\n",
    "        \n",
    "        log.info('Inference Time of SSD MobileNet V2 {}: {} seconds'.format(name, inference_time))\n",
    "        # Calculate FPS from inference time\n",
    "        inference_engine_fps = 1 / inference_time\n",
    "        \n",
    "        inference_engine_fps_collected.append(inference_engine_fps)\n",
    "\n",
    "    # Calculate the average FPS for all inferences\n",
    "    inference_engine_avg_fps = (sum(inference_engine_fps_collected) * BATCH) / (NUM_RUNS)\n",
    "    \n",
    "    PERFORMANCE[name] = inference_engine_avg_fps\n",
    "\n",
    "    log.info('{} frame per seconds (FPS): {}'.format(name, inference_engine_avg_fps))\n",
    "    \n",
    "    return inference_engine_avg_fps, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ INFO ] Creating Inference Engine Core\n",
      "[ INFO ] Reading IR...\n",
      "[ INFO ] COMMON: image preprocessing\n",
      "[ INFO ] Loading IR to the plugin...\n",
      "[ INFO ] Current shape: (1, 3, 300, 300)\n",
      "[ INFO ] INFERENCE ENGINE SPECIFIC: no post-processing\n",
      "[ INFO ] Inference Time of SSD MobileNet V2 IE  on CPU: 0.010700225830078125 seconds\n",
      "[ INFO ] IE  on CPU frame per seconds (FPS): 93.45597147950089\n"
     ]
    }
   ],
   "source": [
    "device = 'CPU'\n",
    "\n",
    "# Run the inference \n",
    "inference_engine_average_fps, inference_engine_predictions = ie_main(IE_MODEL_FP32_XML, \n",
    "                                                                     IE_MODEL_FP32_BIN, \n",
    "                                                                     device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_engine_predictions[0] # get data for the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import parse_od_output, draw_image\n",
    "\n",
    "draw_image(IMAGE, inference_engine_predictions, IE_RESULT_IMAGE, color=(255, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Image class from display to show an image\n",
    "from IPython.display import Image\n",
    "\n",
    "# Show the image in the notebok\n",
    "Image(filename=IE_RESULT_IMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions from Matplotlib to show barcharts\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "def show_results_interactively(tf_image: str, ie_image: str, combination_image: str, ie_fps:float, tf_fps:float):\n",
    "    \"\"\"\n",
    "    Takes paths to three images and shows them with Matplotlib on one screen.\n",
    "    \"\"\"\n",
    "    _ = plt.figure(figsize=(30, 10))\n",
    "    gs1 = gridspec.GridSpec(1, 3)\n",
    "    gs1.update(wspace=0.25, hspace=0.05)\n",
    "\n",
    "    titles = [\n",
    "        '(a) Tensorflow',\n",
    "        '(b) Inference Engine',\n",
    "        '(c) TensorFlow and Inference Engine\\n predictions are identical'\n",
    "    ]\n",
    "\n",
    "    for i, path in enumerate([tf_image, ie_image, combination_image]):\n",
    "        img_resized = cv2.imread(path)\n",
    "        ax_plot = plt.subplot(gs1[i])\n",
    "        ax_plot.axis(\"off\")\n",
    "        addon = ' '\n",
    "        if i == 1:\n",
    "            addon += '{:4.3f}'.format(ie_fps) + '(FPS)'\n",
    "        elif i == 0:\n",
    "            addon += '{:4.3f}'.format(tf_fps) + '(FPS)'\n",
    "\n",
    "        ax_plot.text(0.5, -0.5, titles[i] + addon,\n",
    "                     size=28, ha=\"center\",\n",
    "                     transform=ax_plot.transAxes)\n",
    "        ax_plot.imshow(cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import draw_image\n",
    "\n",
    "# Draw inference results from the Inference Engine in the image with TensorFlow inference results\n",
    "draw_image(TF_RESULT_IMAGE, inference_engine_predictions, COMBO_RESULT_IMAGE, color=(255, 0, 0))\n",
    "\n",
    "show_results_interactively(tf_image=TF_RESULT_IMAGE,\n",
    "                           ie_image=IE_RESULT_IMAGE,\n",
    "                           combination_image=COMBO_RESULT_IMAGE,\n",
    "                           ie_fps=inference_engine_average_fps,\n",
    "                           tf_fps=tensorflow_average_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import show_performance\n",
    "\n",
    "performance_data = {\n",
    "    'TF on CPU': tensorflow_average_fps,\n",
    "    'IE on CPU': inference_engine_average_fps\n",
    "}\n",
    "\n",
    "show_performance(performance_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pictures/ie_fusing.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oh, this is good - we got the same results in one image. But it is only ONE image. We need check accuracy on the whole dataset. So how can we do this?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 11: Accuracy Checker - OpenVINO&trade; Accuracy Validation Framework<a id='s10'></a>\n",
    "\n",
    "![](pictures/accuracy_check.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace variables to the real path in the Accuracy Checker config:\n",
    "!WORKSHOP_PATH=$(pwd) envsubst '\\${WORKSHOP_PATH}' <data/configs/accuracy_checker_config_tf_template.yml >data/configs/accuracy_checker_config_tf.yml\n",
    "\n",
    "# Run the Accuracy Checker:\n",
    "!accuracy_check -c data/configs/accuracy_checker_config_tf.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Coffee Break***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace variables to the real path in the Accuracy Checker config:\n",
    "!WORKSHOP_PATH=$(pwd) envsubst '\\${WORKSHOP_PATH}' <data/configs/accuracy_checker_config_template.yml >data/configs/accuracy_checker_config.yml\n",
    "\n",
    "# Run the Accuracy Checker:\n",
    "!accuracy_check -c data/configs/accuracy_checker_config.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat data/configs/accuracy_checker_config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 10: [Quantize the Model to Low Precision](https://docs.openvinotoolkit.org/latest/_compression_algorithms_quantization_README.html)<a id='s10'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pictures/quantization.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pictures/quantize.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 11: [Post-Trainig Optimization Toolkit](https://docs.openvinotoolkit.org/latest/_README.html)<a id='s11'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Post-Training Optimization Toolkit includes standalone command-line tool and Python* API that provide the following key features:\n",
    "\n",
    "* Two supported post-training quantization algorithms: fast [DefaultQuantization](https://docs.openvinotoolkit.org/latest/_compression_algorithms_quantization_default_README.html) and precise [AccuracyAwareQuantization](https://docs.openvinotoolkit.org/latest/_compression_algorithms_quantization_accuracy_aware_README.html).\n",
    "as well as multiple experimental methods including global optimization.\n",
    "* Symmetric and asymmetric quantization schemes. For more details, see the [Quantization](https://docs.openvinotoolkit.org/latest/_compression_algorithms_quantization_README.html) section.\n",
    "* Compression for different hardware targets such as CPU, GPU.\n",
    "* Per-channel quantization for Convolutional and Fully-Connected layers.\n",
    "* Multiple domains: Computer Vision, Recommendation Systems.\n",
    "* Ability to implement custom calibration pipeline via supported [API](https://docs.openvinotoolkit.org/latest/_sample_README.html).\n",
    "\n",
    "<br>   \n",
    "\n",
    "![](pictures/pot.png)\n",
    "\n",
    "<br>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON files containing all info needed for calibration:\n",
    "    1. Model parameters (name, path to full precision IR)\n",
    "    2. Engine Parameters (e.g. preprocessing parameters, dataset path, etc.)\n",
    "        2.1 Use accuracy checker .yml config\n",
    "        2.2 Define all the required AccuracyChecker parameters directly in the JSON file\n",
    "    3 .Compression parameters (optimization algorithm and its parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DefaultQuantization algorithm performs a fast but at the same time accurate INT8 calibration of NNs. It consists of three algorithms that are sequentially applied to a model:\n",
    "*  ActivationChannelAlignment - Used as a preliminary step before quantization and allows you to align ranges of output activations of Convolutional layers in order to reduce the quantization error.\n",
    "*  MinMaxQuantization - This is a vanilla quantization method that automatically inserts `FakeQuantize` operations into the model graph based on the specified  target hardware and initializes them\n",
    "using statistics collected on the calibration dataset.\n",
    "*  BiasCorrection - Adjusts biases of Convolutional and Fully-Connected layers based on the quantization error of the layer in order to make the overall error unbiased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ${INTEL_OPENVINO_DIR}/deployment_tools/tools/post_training_optimization_toolkit/main.py \\\n",
    "-c data/configs/default/quantization_config.json \\\n",
    "--output-dir data/public/ssd_mobilenet_v2_coco/INT8/default \\\n",
    "--direct-dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat data/configs/default/quantization_config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pictures/quantized_ir.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [FakeQuantize Layer](https://docs.openvinotoolkit.org/latest/_docs_MO_DG_prepare_model_convert_model_IR_V10_opset1.html#FakeQuantize) <a name=\"FakeQuantize\"></a>\n",
    "\n",
    "**Name**: *FakeQuantize*\n",
    "\n",
    "**Category**: *Layer*\n",
    "\n",
    "**Short description**: *FakeQuantize* layer is element-wise linear quantization of floating-point input values into a discrete set of floating-point values.\n",
    "\n",
    "**Detailed description**: Input and output ranges as well as the number of levels of quantization are specified by dedicated inputs and attributes. There can be different limits for each element or groups of elements (channels) of the input blobs. Otherwise, one limit applies to all elements. It depends on shape of inputs that specify limits and regular broadcasting rules applied for input blobs. The output of the operator is a floating-point number of the same type as the input blob. In general, there are four values that specify quantization for each element: *input_low*, *input_high*, *output_low*, *output_high*. *input_low* and *input_high* parameters specify the input range of quantization. All input values that are outside this range are clipped to the range before actual quantization. *output_low* and *output_high* specify minimum and maximum quantized values at the output.\n",
    "\n",
    "**Parameters**: *Quantize* layer parameters are specified in the `data` node, which is a child of the `layer` node.\n",
    "\n",
    "* **Parameter name**: *levels*\n",
    "\n",
    "  * **Description**: *levels* is the number of quantization levels.\n",
    "  * **Range of values**: an integer greater than or equal to 2\n",
    "  * **Type**: `int`\n",
    "  * **Default value**: None\n",
    "  * **Required**: *yes*\n",
    "\n",
    "**Inputs**:\n",
    "\n",
    "*   **1**: `X` - multidimensional input blob to quantize. Required.\n",
    "\n",
    "*   **2**: `input_low` - minimum limit for input value. The shape must be broadcastable to the shape of `X`. Required.\n",
    "\n",
    "*   **3**: `input_high` - maximum limit for input value. Can be the same as `input_low` for binarization. The shape must be broadcastable to the shape of `X`. Required.\n",
    "\n",
    "*   **4**: `output_low` - minimum quantized value. The shape must be broadcastable to the shape of `X`. Required.\n",
    "\n",
    "*   **5**: `output_high` - maximum quantized value. The shape must be broadcastable to the of `X`. Required.\n",
    "\n",
    "**Mathematical Formulation**\n",
    "\n",
    "Each element of the output is defined as the result of the following expression:\n",
    "\n",
    "```python\n",
    "if x <= input_low:\n",
    "    output = output_low\n",
    "elif x > input_high:\n",
    "    output = output_high\n",
    "else:\n",
    "    # input_low < x <= input_high\n",
    "    output = round((x - input_low) / (input_high - input_low) * (levels-1)) / (levels-1) * (output_high - output_low) + output_low\n",
    "```\n",
    "\n",
    "**Example**\n",
    "```xml\n",
    "<layer … type=\"FakeQuantize\"…>\n",
    "    <data levels=\"2\"/>\n",
    "    <input>\n",
    "        <port id=\"0\">\n",
    "            <dim>1</dim>\n",
    "            <dim>64</dim>\n",
    "            <dim>56</dim>\n",
    "            <dim>56</dim>\n",
    "        </port>\n",
    "        <port id=\"1\">\n",
    "            <dim>1</dim>\n",
    "            <dim>64</dim>\n",
    "            <dim>1</dim>\n",
    "            <dim>1</dim>\n",
    "        </port>\n",
    "        <port id=\"2\">\n",
    "            <dim>1</dim>\n",
    "            <dim>64</dim>\n",
    "            <dim>1</dim>\n",
    "            <dim>1</dim>\n",
    "        </port>\n",
    "        <port id=\"3\">\n",
    "            <dim>1</dim>\n",
    "            <dim>1</dim>\n",
    "            <dim>1</dim>\n",
    "            <dim>1</dim>\n",
    "        </port>\n",
    "        <port id=\"4\">\n",
    "            <dim>1</dim>\n",
    "            <dim>1</dim>\n",
    "            <dim>1</dim>\n",
    "            <dim>1</dim>\n",
    "        </port>\n",
    "    </input>\n",
    "    <output>\n",
    "        <port id=\"5\">\n",
    "            <dim>1</dim>\n",
    "            <dim>64</dim>\n",
    "            <dim>56</dim>\n",
    "            <dim>56</dim>\n",
    "        </port>\n",
    "    </output>\n",
    "</layer>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'CPU'\n",
    "ie_avg_fps, predictions = ie_zmain(IE_MODEL_DEFAULT_INT8_XML, IE_MODEL_DEFAULT_INT8_BIN, device, 'INT8 D')\n",
    "\n",
    "draw_image(TF_RESULT_IMAGE, predictions, COMBO_RESULT_IMAGE, color=(0, 0, 255))\n",
    "\n",
    "show_results_interactively(tf_image=TF_RESULT_IMAGE,\n",
    "                           ie_image=IE_RESULT_IMAGE,\n",
    "                           combination_image=COMBO_RESULT_IMAGE,\n",
    "                           ie_fps=ie_avg_fps,\n",
    "                           tf_fps=tensorflow_average_fps)\n",
    "\n",
    "show_performance(PERFORMANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace variables to the real path in the Accuracy Checker config:\n",
    "!WORKSHOP_PATH=$(pwd) envsubst '\\${WORKSHOP_PATH}' <data/configs/default/accuracy_checker_config_template.yml >data/configs/default/accuracy_checker_config.yml\n",
    "\n",
    "# Run the Accuracy Checker\n",
    "!accuracy_check -c data/configs/default/accuracy_checker_config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 12: [AccuracyAware Algorithm](https://docs.openvinotoolkit.org/latest/_compression_algorithms_quantization_accuracy_aware_README.html)<a id='s12'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ${INTEL_OPENVINO_DIR}/deployment_tools/tools/post_training_optimization_toolkit/main.py \\\n",
    "-c data/configs/accuracy_aware/quantization_config.json \\\n",
    "--output-dir data/public/ssd_mobilenet_v2_coco/INT8/acuracy_aware \\\n",
    "--direct-dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat data/configs/accuracy_aware/quantization_config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The model gets fully quantized using the DefaultQuantization algorithm.\n",
    "2. The quantized and full-precision models are compared on a subset of the validation set in order to find mismatches in the target accuracy metric. A ranking subset is extracted based on the mismatches.\n",
    "3. A layer-wise ranking is performed in order to get a contribution of each quantized layer into the accuracy drop.\n",
    "4. Based on the ranking, the most \"problematic\" layer is reverted back to the original precision. This change is followed by the evaluation of the obtained model on the full validation set in order to get a new accuracy drop.\n",
    "5. If the accuracy criteria are satisfied for all pre-defined accuracy metrics, the algorithm finishes. Otherwise, it continues reverting the next \"problematic\" layer.\n",
    "6. It may happen that regular reverting does not get any accuracy improvement or even worsen the accuracy. Then the re-ranking is triggered as it is described in step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'CPU'\n",
    "ie_avg_fps, predictions = ie_main(IE_MODEL_AA_INT8_XML, IE_MODEL_AA_INT8_BIN, device, 'INT8 AA')\n",
    "\n",
    "draw_image(TF_RESULT_IMAGE, predictions, COMBO_RESULT_IMAGE, color=(0, 0, 255))\n",
    "\n",
    "show_results_interactively(tf_image=TF_RESULT_IMAGE,\n",
    "                           ie_image=IE_RESULT_IMAGE,\n",
    "                           combination_image=COMBO_RESULT_IMAGE,\n",
    "                           ie_fps=ie_avg_fps,\n",
    "                           tf_fps=tensorflow_average_fps)\n",
    "\n",
    "show_performance(PERFORMANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace variables to the real path in the Accuracy Checker config:\n",
    "!WORKSHOP_PATH=$(pwd) envsubst '\\${WORKSHOP_PATH}' <data/configs/accuracy_aware/accuracy_checker_config_template.yml >data/configs/accuracy_aware/accuracy_checker_config.yml\n",
    "\n",
    "# Run the Accuracy Checker\n",
    "!accuracy_check -c data/configs/accuracy_aware/accuracy_checker_config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 13: VNNI - [Deep Learning Boost](https://www.intel.ai/intel-deep-learning-boost/)<a id='s13'></a>\n",
    "\n",
    "![](pictures/dl_boost.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 14: [Get Even Better Performance](https://docs.openvinotoolkit.org/latest/_docs_performance_benchmarks.html)<a id='s14'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great performance results! But if you want the best performance, use C++."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a [C++ benchmark application](https://docs.openvinotoolkit.org/latest/_inference_engine_samples_benchmark_app_README.html) in Inference samples. Let's build it from sources and try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/samples/cpp/build\n",
    "! cd ${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/samples/cpp/build && cmake .. && make benchmark_app -j8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/samples/cpp/build/intel64/Release/benchmark_app -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/samples/cpp/build/intel64/Release/benchmark_app -m data/public/ssd_mobilenet_v2_coco/FP32/ssd_mobilenet_v2_coco.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERFORMANCE['OpenVINO IE Benchmark INT8'] = 139.86\n",
    "show_performance(PERFORMANCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 15: Practice<a id='s15'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Contains all data for the workshop\n",
    "WORKSHOP_DATA_PATH = os.path.join('.', 'data')\n",
    "\n",
    "# Path to the downloaded TensorFlow image\n",
    "SSD_ASSETS = os.path.join(WORKSHOP_DATA_PATH, 'public', 'ssd_mobilenet_v2_coco')\n",
    "\n",
    "# Path to the Inference Engine FP32 model\n",
    "# But you can replace FP32 model to INT8\n",
    "MODEL_PATH_XML = os.path.join(SSD_ASSETS, 'FP32', 'ssd_mobilenet_v2_coco.xml')\n",
    "MODEL_PATH_BIN = os.path.join(SSD_ASSETS, 'FP32', 'ssd_mobilenet_v2_coco.bin')\n",
    "\n",
    "DEVICE = 'CPU'\n",
    "\n",
    "DATA_PATH = os.path.join('practice', 'data')\n",
    "INPUT_VIDEO = os.path.join(DATA_PATH, 'input.mp4')\n",
    "OUTPUT_VIDEO = os.path.join(DATA_PATH, 'output.MP4')\n",
    "\n",
    "LABELS_PATH = os.path.join(DATA_PATH, 'coco_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "# Show a source videos\n",
    "HTML(\"\"\"<video width=\"600\" height=\"400\" controls><source src=\"{}\" type=\"video/mp4\"></video>\"\"\".format(INPUT_VIDEO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prapare_out_video_stream(input_video_stream):\n",
    "    width  = int(input_video_stream.get(3))\n",
    "    height = int(input_video_stream.get(4))\n",
    "    return cv2.VideoWriter(OUTPUT_VIDEO, cv2.VideoWriter_fourcc(*'X264'), 20, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Import Inference Engine\n",
    "from openvino.inference_engine import IECore, IENetwork\n",
    "\n",
    "# Work with OpenVINO Inference Engine starts with creating an instance of IECore. \n",
    "# This class represents an Inference Engine entity \n",
    "# and allows you to manipulate with plugins using unified interfaces \n",
    "# You need create an instance of this class\n",
    "ie = \n",
    "\n",
    "# The next step is reading the prepared model\n",
    "# The IENetwork class is designed to work with a model in the Inference Engine\n",
    "# This class contains information about the network model read from the Intermediate Representation\n",
    "# and allows you to manipulate with some model parameters such as layers affinity and output layers\n",
    "\n",
    "# You need create an instance of the IENetwork class.\n",
    "# A constructor of this class has two parameters: \n",
    "# 1. path to xml file of the model \n",
    "# 2. path to bin file of the model\n",
    "net = \n",
    "\n",
    "# For inference of the model you need know input layers of the model\n",
    "# The object `net` contains information about inputs of the network in a property `inputs` \n",
    "# `inputs` is a dictionary: key - name of the input layer, volume - representation of the input network\n",
    "# In this case you need get only name of the input. `input_blob` should be string\n",
    "input_blob = \n",
    "\n",
    "print('Input layer of the network is {}'.format(input_blob))\n",
    "\n",
    "# Get shape (dimensions) of the input layer of the network\n",
    "# n - number of batches\n",
    "# c - number of an input image channels (usualy 3 - R, G and B) \n",
    "# h - height\n",
    "# w - width\n",
    "n, c, h, w = net.inputs[input_blob].shape\n",
    "\n",
    "print('Input shape of the network: [{}, {}, {}, {}]'.format(n, c, h, w))\n",
    "\n",
    "# Get names of output layers of the network\n",
    "# For more easy processing of inferences result it will be good if we know names of outputs\n",
    "# The object `net` contains information about outputs in the same way as inputs\n",
    "# There is property `outputs` in the class IENetwork\n",
    "# You need get name of the output. `out_blob` should be string \n",
    "out_blob = \n",
    "\n",
    "print('Output layer of the network: {}'.format(out_blob))\n",
    "\n",
    "# Load names of COCO classes from the file \n",
    "with open(LABELS_PATH, 'r') as f:\n",
    "    labels_map = [x.strip() for x in f]\n",
    "\n",
    "\n",
    "# It's time to loading the network to the device.\n",
    "# For this you should use the instance of IECore.\n",
    "# The class IECore has a special function for loading network to a device: `load_network`\n",
    "# This function prepares the network for inference one on the device \n",
    "# and return an instance of the prepared to inference (execution) network . \n",
    "# This function has many parameters but for this case you need know only about two:\n",
    "# network - instance of the IENetwork\n",
    "# device_name - string, contains device name for inference the model: CPU, GPU and e.t.c.\n",
    "network_loaded_to_device = \n",
    "\n",
    "# Open an input video\n",
    "input_video_stream = cv2.VideoCapture(INPUT_VIDEO)\n",
    "\n",
    "# Create an output video stream\n",
    "out = prapare_out_video_stream(input_video_stream)\n",
    "\n",
    "# Loop over frames in the input video\n",
    "while input_video_stream.isOpened():\n",
    "    \n",
    "    # Read the next frame from the intput video \n",
    "    ret, frame = input_video_stream.read()\n",
    "    # Check if the video is over\n",
    "    if not ret:\n",
    "        # Exit from the loop if the video is over\n",
    "        break \n",
    "    # Get height and width of the frame\n",
    "    frame_h, frame_w = frame.shape[:2]\n",
    "    \n",
    "    # Resize the frame to the network input \n",
    "    in_frame = cv2.resize(frame, (w, h))\n",
    "    \n",
    "    # Change the data layout from HWC to CHW\n",
    "    in_frame = in_frame.transpose((2, 0, 1))  \n",
    "    \n",
    "    # Reshape the frame to the network input \n",
    "    in_frame = in_frame.reshape((n, c, h, w))\n",
    "    \n",
    "    # For inference the frame you need prepare the data\n",
    "    # This must be a dictionary: \n",
    "    #   key - name of the input layer (you get this early)\n",
    "    #   value - input data (the prepared frame)  \n",
    "    feed_dict = {\n",
    "        \n",
    "    }\n",
    "    \n",
    "    # All ready for do the main thing - Inference!\n",
    "    # You read and loaded the Network to the device, prepared input data and ready to do infer\n",
    "    # To do inference you should call the `infer` function of the `network_loaded_to_device` var \n",
    "    # We must set input data - the dictionary \n",
    "    # and read the result of the inference from the output layer of the execution network \n",
    "    inference_result = \n",
    "    \n",
    "    # Greate! The `inference_result` variable contains output data after inference of the network\n",
    "    # `inference_result` is dictionary, where key is name of the output name, and value is data from the blob\n",
    "    # Then you need to Iterate over all discovered objects. \n",
    "    for obj in inference_result[out_blob][0][0]:\n",
    "        # This loop contains processing of the inference results. \n",
    "        # The output layer of the SSD MobileNet V2 is DetectionOutput layer\n",
    "        # Data layout of this layer (and `obj` variable):\n",
    "        # element 0 - is batch ID - it is not important in this case\n",
    "        # emenent 1 - is class ID of found object \n",
    "        # emenent 2 - confidence of the object\n",
    "        # emenent 3 and 4 - coordinates of upper left corner of the box for object\n",
    "        # emenent 5 and 6 - coordinates of down right corner of the box for object\n",
    "        \n",
    "        threshold = 0.0001\n",
    "        # Get the confidence of the found object \n",
    "        confidence = \n",
    "        \n",
    "        # Draw a bounding box only for objects the confidence of which is greater than a specified threshold\n",
    "        if confidence > threshold:\n",
    "            # Get coordinates of the discovered object\n",
    "            # and scale it to the original size of the frame\n",
    "            xmin = int( * frame_w)\n",
    "            ymin = int( * frame_h)\n",
    "            \n",
    "            xmax = int( * frame_w)\n",
    "            ymax = int( * frame_h)\n",
    "\n",
    "            # Get class ID of the discovered object\n",
    "            class_id = int()\n",
    "\n",
    "            # Get confidence for the discovered object\n",
    "            confidence = round(confidence * 100, 1)\n",
    "\n",
    "            # Draw a box and label\n",
    "            color = (min(class_id * 12.5, 255), min(class_id * 7, 255), min(class_id * 5, 255))\n",
    "            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "\n",
    "            # Get label of the class\n",
    "            label = labels_map[class_id]\n",
    "\n",
    "            # Create the title of the object\n",
    "            text = '{}: {}% '.format(label, confidence)\n",
    "\n",
    "            # Put the title to the frame\n",
    "            cv2.putText(frame, text, (xmin, ymin - 7), cv2.FONT_HERSHEY_COMPLEX, 2, color, 2)\n",
    "\n",
    "    # Write the resulting frame to the output stream\n",
    "    out.write(frame)\n",
    "\n",
    "# Save the resulting video\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# Show a source videos\n",
    "HTML(\"\"\"<video width=\"600\" height=\"400\" controls><source src=\"{}\" type=\"video/mp4\"></video>\"\"\".format(OUTPUT_VIDEO))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
