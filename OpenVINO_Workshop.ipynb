{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenVINO: Демократизация оптимизации нейронных сетей\n",
    "![](workshop/pictures/openvino_start.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenVINO Toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](workshop/pictures/openvino_toolkit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of this workshop is initializing OpenVINO environment in this Jupyter notebook. \n",
    "The OpenVINO 2020.1 package have been installed to `intel/openvino/` already.\n",
    "For initializing the OpenVINO environment you should run the script `intel/openvino/bin/setupvars.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash intel/openvino/bin/setupvars.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to check the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo LD_LIBRARY_PATH is $LD_LIBRARY_PATH\n",
    "!echo\n",
    "!echo PYTHONPATH is $PYTHONPATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see there are paths to the OpenVINO in LD_LIBRARY_PATH and PYTHONPATH variables.\n",
    "So you can already use the OpenVINO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Model Zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](workshop/pictures/models.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OpenVINO package contains tools for easy download model from [OpenModelZoo](https://github.com/opencv/open_model_zoo) \n",
    "and convert the model to Intermediate Representation that OpenVINO supports\n",
    "\n",
    "To see all available models (both public open-sourse from original frameworks (TensorFlow, Caffe, MxNet, Pytorch e.t.c),\n",
    "and made in Intel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ${INTEL_OPENVINO_DIR}/deployment_tools/open_model_zoo/tools/downloader/downloader.py --print_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For downloading any of these models you need to use downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ${INTEL_OPENVINO_DIR}/deployment_tools/open_model_zoo/tools/downloader/downloader.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to download an object detection model `ssd_mobilenet_v2_coco`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3  ${INTEL_OPENVINO_DIR}/deployment_tools/open_model_zoo/tools/downloader/downloader.py \\\n",
    "                                                                                --name ssd_mobilenet_v2_coco \\\n",
    "                                                                                --output_dir ./workshop/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Downloader has downloaded the model to `./workshop/data/public/ssd_mobilenet_v2_coco/ssd_mobilenet_v2_coco_<DATE>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la ./workshop/data/public/ssd_mobilenet_v2_coco/ssd_mobilenet_v2_coco_<DATE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the Model Downloader downloaded the model in TensorFlow format.\n",
    "You need convert this model to IR format. \n",
    "For this you need run converter script\n",
    "converter script runs the Model Optimizer with right parameters to converting the model with to IR.\n",
    "Of course  we can run the Model Optimizer directly. But for this we need pass right arguments to the Model Optimizer.\n",
    "All information about converting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ${INTEL_OPENVINO_DIR}/deployment_tools/open_model_zoo/tools/downloader/converter.py \\\n",
    "                                                         --name ssd_mobilenet_v2_coco \\\n",
    "                                                         --download_dir ./workshop/data \\\n",
    "                                                         --output_dir ./workshop/data \\\n",
    "                                                         --precisions FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la ./workshop/data/public/ssd_mobilenet_v2_coco/FP32/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find a command of running OpenVINO Model Optimizer in the output of the converter.py script.\n",
    "You can try this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ${INTEL_OPENVINO_DIR}/deployment_tools/model_optimizer/mo.py \\\n",
    "    --output_dir=./workshop/data/public/ssd_mobilenet_v2_coco/FP32 \\\n",
    "    --reverse_input_channels \\\n",
    "    --model_name=ssd_mobilenet_v2_coco \\\n",
    "    --transformations_config=${INTEL_OPENVINO_DIR}/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json \\\n",
    "    --tensorflow_object_detection_api_pipeline_config=./workshop/data/public/ssd_mobilenet_v2_coco/ssd_mobilenet_v2_coco_2018_03_29/pipeline.config \\\n",
    "    --output=detection_classes,detection_scores,detection_boxes,num_detections \\\n",
    "    --input_model=./workshop/data/public/ssd_mobilenet_v2_coco/ssd_mobilenet_v2_coco_2018_03_29/frozen_inference_graph.pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some function are needed for the next part of the workshop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def read_resize_image(path_to_image: str, width: int, height: int):\n",
    "    \"\"\"\n",
    "    Takes an image and resizes it to the given dimensions\n",
    "    \"\"\"\n",
    "    #Load the image \n",
    "    raw_image = cv2.imread(path_to_image)\n",
    "    #Return the resized to (width, height) size image  \n",
    "    return cv2.resize(raw_image, (width, height), interpolation=cv2.INTER_NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_performance(performance_data: dict):\n",
    "    \"\"\"\n",
    "    Takes dictionary contains name of configurations as keys and FPS for it as values\n",
    "    \"\"\"\n",
    "    y_pos = np.arange(len(performance_data))\n",
    "    performance = [fps for case, fps in performance_data.items()]\n",
    "    plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "    plt.xticks(y_pos, performance_data.keys())\n",
    "    plt.ylabel('FPS')\n",
    "    plt.title('Configurations')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_image(original_image: str, res: tuple, path_to_image: str, prob_threshold: float=0.8, color: tuple=(0, 255, 0)):\n",
    "    \"\"\"\n",
    "    Takes a path to the image and bounding boxes. Draws those boxes on the new image and saves it\n",
    "    \"\"\"\n",
    "    raw_image = cv2.imread(original_image)\n",
    "    initial_w = raw_image.shape[1]\n",
    "    initial_h = raw_image.shape[0]\n",
    "    labels_map = {\n",
    "        18: 'dog',\n",
    "        21: 'cat'\n",
    "    }\n",
    "    for obj in res[0][0]:\n",
    "        # Draw only objects when probability more than specified threshold\n",
    "        if obj[2] > prob_threshold:\n",
    "            xmin = int(obj[3] * initial_w)\n",
    "            ymin = int(obj[4] * initial_h)\n",
    "            xmax = int(obj[5] * initial_w)\n",
    "            ymax = int(obj[6] * initial_h)\n",
    "            class_id = int(obj[1])\n",
    "            confidence = round(obj[2] * 100, 1)\n",
    "            cv2.rectangle(raw_image, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "            det_label = labels_map[class_id] if labels_map else str(class_id)\n",
    "            box_title = '{} {}%'.format(det_label, confidence)\n",
    "            cv2.putText(raw_image,\n",
    "                        box_title,\n",
    "                        (xmin, ymin - 7),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX, 5, color, cv2.LINE_AA)\n",
    "    cv2.imwrite(path_to_image, raw_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "def show_results_interactively(tf_image, ie_image, combination_image, ie_fps, tf_fps):\n",
    "    \"\"\"\n",
    "    Takes paths to three images and shows them with matplotlib on one screen\n",
    "    \"\"\"\n",
    "    _ = plt.figure(figsize=(30, 10))\n",
    "    gs1 = gridspec.GridSpec(1, 3)\n",
    "    gs1.update(wspace=0.25, hspace=0.05)\n",
    "\n",
    "    titles = [\n",
    "        '(a) Tensorflow',\n",
    "        '(b) Inference Engine',\n",
    "        '(c) TensorFlow and Inference Engine\\n predictions are identical'\n",
    "    ]\n",
    "\n",
    "    for i, path in enumerate([tf_image, ie_image, combination_image]):\n",
    "        img_resized = cv2.imread(path)\n",
    "        ax_plot = plt.subplot(gs1[i])\n",
    "        ax_plot.axis(\"off\")\n",
    "        addon = ' '\n",
    "        if i == 1:\n",
    "            addon += '{:4.3f}'.format(ie_fps) + '(FPS)'\n",
    "        elif i == 0:\n",
    "            addon += '{:4.3f}'.format(tf_fps) + '(FPS)'\n",
    "\n",
    "        ax_plot.text(0.5, -0.5, titles[i] + addon,\n",
    "                     size=28, ha=\"center\",\n",
    "                     transform=ax_plot.transAxes)\n",
    "        ax_plot.imshow(cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(path_to_model: str):\n",
    "    \"\"\"\n",
    "    Creates in memory graph in TensorFlow\n",
    "    \"\"\"\n",
    "    tf.reset_default_graph()\n",
    "    graph = tf.Graph()\n",
    "    graph_def = tf.GraphDef()\n",
    "\n",
    "    with open(path_to_model, \"rb\") as model_file:\n",
    "        graph_def.ParseFromString(model_file.read())\n",
    "\n",
    "    nodes_to_clear_device = graph_def.node if isinstance(\n",
    "        graph_def, tf.GraphDef) else graph_def.graph_def.node\n",
    "    for node in nodes_to_clear_device:\n",
    "        node.device = \"\"\n",
    "\n",
    "    with graph.as_default():\n",
    "        tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "    log.info(\"tf graph was created\")\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import graph_io\n",
    "\n",
    "import numpy as np\n",
    "import logging as log\n",
    "import time\n",
    "import os\n",
    "\n",
    "def children(op_name: str, graph: tf.Graph):\n",
    "    \"\"\"\n",
    "    Get operation node children.\n",
    "    \"\"\"\n",
    "    op = graph.get_operation_by_name(op_name)\n",
    "    return set(op for out in op.outputs for op in out.consumers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_graph(graph_def):\n",
    "    unlikely_output_types = [\n",
    "        'Const', 'Assign',\n",
    "        'NoOp', 'Placeholder',\n",
    "        'Assert', 'switch_t', 'switch_f'\n",
    "    ]\n",
    "    placeholders = dict()\n",
    "    outputs = list()\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():  # pylint: disable=not-context-manager\n",
    "        tf.import_graph_def(graph_def, name='')\n",
    "    for node in graph.as_graph_def().node:  # pylint: disable=no-member\n",
    "        if node.op == 'Placeholder':\n",
    "            node_dict = dict()\n",
    "            node_dict['type'] = tf.DType(node.attr['dtype'].type).name\n",
    "            new_shape = tf.TensorShape(node.attr['shape'].shape)\n",
    "            node_dict['shape'] = str(new_shape).replace(' ', '').replace('?', '-1')\n",
    "            placeholders[node.name] = node_dict\n",
    "        if len(children(node.name, graph)) == 0:\n",
    "            if node.op not in unlikely_output_types and \\\n",
    "                node.name.split('/')[-1] not in unlikely_output_types:\n",
    "                outputs.append(node.name)\n",
    "    result = dict()\n",
    "    result['inputs'] = placeholders\n",
    "    result['outputs'] = outputs\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_refs(graph: tf.Graph, input_data: dict):\n",
    "    \"\"\"\n",
    "    Return TensorFlow model reference results.\n",
    "    \"\"\"\n",
    "    log.info(\"Running inference with tensorflow ...\")\n",
    "    feed_dict = {}\n",
    "    summary_info = summarize_graph(graph.as_graph_def())\n",
    "    input_layers, output_layers = list(summary_info['inputs'].keys()), summary_info['outputs']\n",
    "\n",
    "    data_keys = [key for key in input_data.keys()]\n",
    "    if sorted(input_layers) != sorted(data_keys):\n",
    "        raise ValueError('input data keys: {0} do not match input '\n",
    "                         'layers of network: {1}'.format(data_keys, input_layers))\n",
    "\n",
    "    for input_layer_name in input_layers:\n",
    "        tensor = graph.get_tensor_by_name(input_layer_name + ':0')\n",
    "        feed_dict[tensor] = input_data[input_layer_name]\n",
    "    output_tensors = []\n",
    "    for name in output_layers:\n",
    "        tensor = graph.get_tensor_by_name(name + ':0')\n",
    "        output_tensors.append(tensor)\n",
    "\n",
    "    log.info(\"Running tf.Session\")\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1' # force inference on CPU\n",
    "    with graph.as_default():\n",
    "        with tf.Session(graph=graph) as session:\n",
    "            inference_start = time.time()\n",
    "            outputs = session.run(output_tensors, feed_dict=feed_dict)\n",
    "            inference_end = time.time()\n",
    "    res = dict(zip(output_layers, outputs))\n",
    "    log.info(\"TensorFlow reference collected successfully\\n\")\n",
    "    return res, inference_end - inference_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_od_output(data: dict):\n",
    "    predictions = []\n",
    "    num_batches = len(data['detection_boxes'])\n",
    "    target_layers = ['num_detections', 'detection_classes',\n",
    "                     'detection_scores', 'detection_boxes']\n",
    "\n",
    "    for b in range(num_batches):\n",
    "        predictions.append([])\n",
    "        num_detections = int(data['num_detections'][b])\n",
    "        detection_classes = data['detection_classes'][b]\n",
    "        detection_scores = data['detection_scores'][b]\n",
    "        detection_boxes = data['detection_boxes'][b]\n",
    "        for i in range(num_detections):\n",
    "            obj = [\n",
    "                b, detection_classes[i], detection_scores[i],\n",
    "                detection_boxes[i][1], detection_boxes[i][0],\n",
    "                detection_boxes[i][3], detection_boxes[i][2]\n",
    "            ]\n",
    "            predictions[b].append(obj)\n",
    "    predictions = np.asarray(predictions)\n",
    "    new_shape = (1, 1, predictions.shape[0] * predictions.shape[1], predictions.shape[2])\n",
    "    predictions = np.reshape(predictions, newshape=new_shape)\n",
    "    parsed_data = {'tf_detections': predictions}\n",
    "    for layer, blob in data.items():\n",
    "        if layer not in target_layers:\n",
    "            parsed_data.update({layer: blob})\n",
    "    return parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_main(path_to_model: str, path_to_original_image: str, batch: int = 1):\n",
    "    \"\"\"\n",
    "    Entrypoint for inferencing with TensorFlow\n",
    "    \"\"\"\n",
    "    log.info('COMMON: image preprocessing')\n",
    "    width = 300\n",
    "    resized_image = read_resize_image(path_to_original_image, width, width)\n",
    "    \n",
    "    reshaped_image = np.reshape(resized_image, (width, width, 3))\n",
    "    batched_image = np.array([reshaped_image for _ in range(batch)])\n",
    "    \n",
    "    log.info('Current shape: {}'.format(batched_image.shape))\n",
    "\n",
    "    log.info('TENSORFLOW SPECIFIC: Loading a model with TensorFLow')\n",
    "    graph = load_graph(path_to_model)\n",
    "\n",
    "    input_data = {\n",
    "        'image_tensor': batched_image,\n",
    "    }\n",
    "\n",
    "    raw_results, delta = get_refs(graph, input_data)\n",
    "    log.info('TENSORFLOW SPECIFIC: Plain inference finished')\n",
    "\n",
    "    log.info('TENSORFLOW SPECIFIC: Post processing started')\n",
    "    processed_results = parse_od_output(raw_results)\n",
    "    log.info('TENSORFLOW SPECIFIC: Post processing finished')\n",
    "\n",
    "    return processed_results['tf_detections'], delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.inference_engine import IENetwork, IEPlugin, IECore\n",
    "\n",
    "def ie_main(path_to_model_xml: str, path_to_model_bin: str, path_to_original_image: str, device='CPU', batch=1):\n",
    "    log.info('COMMON: image preprocessing')\n",
    "    width = 300\n",
    "    image = read_resize_image(path_to_original_image, width, width)\n",
    "\n",
    "    # First create Network (Note you need to provide model in IR previously converted with Model Optimizer)\n",
    "    log.info(\"Reading IR...\")\n",
    "    net = IENetwork(model=path_to_model_xml, weights=path_to_model_bin)\n",
    "\n",
    "    # Now let's create IECore() entity \n",
    "    log.info(\"Creating Inference Engine Core\")   \n",
    "    ie = IECore()\n",
    "\n",
    "\n",
    "    input_blob = next(iter(net.inputs))\n",
    "    out_blob = next(iter(net.outputs))\n",
    "\n",
    "    n, c, h, w = net.inputs[input_blob].shape\n",
    "    net.reshape({input_blob: (batch, c, h, w)})\n",
    "    n, c, h, w = net.inputs[input_blob].shape\n",
    "\n",
    "    # Now we load Network to plugin\n",
    "    log.info(\"Loading IR to the plugin...\")\n",
    "    exec_net = ie.load_network(network=net, device_name=device, num_requests=2)\n",
    "\n",
    "    del net\n",
    "\n",
    "    labels_map = None\n",
    "    \n",
    "    # Read and pre-process input image\n",
    "    image = image[..., ::-1]\n",
    "    in_frame = image.transpose((2, 0, 1))  # Change data layout from HWC to CHW\n",
    "    batched_frame = np.array([in_frame for _ in range(batch)])\n",
    "    log.info('Current shape: {}'.format(batched_frame.shape))\n",
    "\n",
    "    # Now we run inference on target device\n",
    "    inference_start = time.time()\n",
    "    res = exec_net.infer(inputs={input_blob: batched_frame})\n",
    "    inference_end = time.time()\n",
    "\n",
    "    log.info('INFERENCE ENGINE SPECIFIC: no post processing')\n",
    "\n",
    "    return res[out_blob], inference_end - inference_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import platform\n",
    "\n",
    "log.basicConfig(format=\"[ %(levelname)s ] %(message)s\", level=log.INFO, stream=sys.stdout)\n",
    "\n",
    "NUM_RUNS = 1\n",
    "BATCH = 1\n",
    "\n",
    "DATA = os.path.join('.', 'workshop', 'data')\n",
    "\n",
    "IMAGE = os.path.join(DATA, 'images', 'input', 'dog.jpg')\n",
    "\n",
    "SSD_ASSETS = os.path.join(DATA, 'public', 'ssd_mobilenet_v2_coco')\n",
    "\n",
    "TF_MODEL = os.path.join(SSD_ASSETS, 'ssd_mobilenet_v2_coco_2018_03_29', 'frozen_inference_graph.pb')\n",
    "TF_RESULT_IMAGE = os.path.join(DATA, 'images', 'output', 'tensorflow_output.png')\n",
    "\n",
    "IE_MODEL_FP32_XML = os.path.join(SSD_ASSETS, 'FP32', 'ssd_mobilenet_v2_coco.xml')\n",
    "IE_MODEL_FP32_BIN = os.path.join(SSD_ASSETS, 'FP32', 'ssd_mobilenet_v2_coco.bin')\n",
    "IE_MODEL_FP16_XML = os.path.join(SSD_ASSETS, 'FP16', 'ssd_mobilenet_v2_coco.xml')\n",
    "IE_MODEL_FP16_BIN = os.path.join(SSD_ASSETS, 'FP16', 'ssd_mobilenet_v2_coco.bin')\n",
    "IE_MODEL_DEFAULT_INT8_XML = os.path.join(SSD_ASSETS, 'INT8', 'default', 'optimized', 'ssd_mobilenet_v2_coco.xml')\n",
    "IE_MODEL_DEFAULT_INT8_BIN = os.path.join(SSD_ASSETS, 'INT8', 'default', 'optimized', 'ssd_mobilenet_v2_coco.bin')\n",
    "IE_MODEL_AA_INT8_XML = os.path.join(SSD_ASSETS, 'INT8', 'acuracy_aware', 'optimized', 'ssd_mobilenet_v2_coco.xml')\n",
    "IE_MODEL_AA_INT8_BIN = os.path.join(SSD_ASSETS, 'INT8', 'acuracy_aware', 'optimized', 'ssd_mobilenet_v2_coco.bin')\n",
    "\n",
    "\n",
    "IE_RESULT_IMAGE = os.path.join(DATA, 'images', 'output', 'inference_engine_output.png')\n",
    "\n",
    "OPENVINO = os.getenv('INTEL_OPENVINO_DIR')\n",
    "if not OPENVINO:\n",
    "    print('Please, install OpenVINO and initialize the environment')\n",
    "    sys.exit(1)\n",
    "    \n",
    "if platform.system() == 'Linux':\n",
    "    ext = '.so'\n",
    "else:\n",
    "    print('You are running this demo on Windows OS or maxOS. However, this is demo for Linux.')\n",
    "    sys.exit(1)\n",
    "\n",
    "COMBO_RESULT_IMAGE = os.path.join(DATA, 'images', 'output', 'combo_output.png')\n",
    "\n",
    "PERFORMANCE = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ie_inference(xml:str, bin:str, device:str, postfix: str):\n",
    "    name = '{f} {p} on {d}'.format(f='IE', p=postfix, d=device)\n",
    "\n",
    "    ie_fps_collected = []\n",
    "\n",
    "    for i in range(NUM_RUNS):\n",
    "        predictions, inf_time = ie_main(xml, bin,\n",
    "                                        IMAGE,\n",
    "                                        device,\n",
    "                                        batch=BATCH)\n",
    "        ie_fps = 1 / inf_time\n",
    "        ie_fps_collected.append(ie_fps)\n",
    "\n",
    "    ie_avg_fps = (sum(ie_fps_collected) * BATCH) / (NUM_RUNS)\n",
    "\n",
    "    PERFORMANCE[name] = ie_avg_fps\n",
    "\n",
    "    log.info('{} FPS: {}'.format(name, ie_avg_fps))\n",
    "\n",
    "    draw_image(IMAGE, predictions, IE_RESULT_IMAGE, color=(0, 0, 255))\n",
    "    \n",
    "    return ie_avg_fps, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framework = 'TF'\n",
    "device = 'CPU'\n",
    "name = '{f} on {d}'.format(f=framework, d=device)\n",
    "\n",
    "tf_fps_collected = []\n",
    "\n",
    "for i in range(NUM_RUNS):\n",
    "    predictions, inf_time = tf_main(TF_MODEL, \n",
    "                                    IMAGE,\n",
    "                                    batch=BATCH)\n",
    "    tf_fps = 1 / inf_time\n",
    "    tf_fps_collected.append(tf_fps)\n",
    "\n",
    "tf_avg_fps = (sum(tf_fps_collected) * BATCH) / (NUM_RUNS)\n",
    "\n",
    "PERFORMANCE[name] = tf_avg_fps\n",
    "\n",
    "log.info('{} FPS: {}'.format(name, tf_avg_fps))\n",
    "\n",
    "draw_image(IMAGE, predictions, TF_RESULT_IMAGE, color=(255, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!accuracy_check -c ./workshop/data/configs/accuracy_checker_config_tf.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'CPU'\n",
    "ie_avg_fps, predictions = ie_inference(IE_MODEL_FP32_XML, IE_MODEL_FP32_BIN, device, '')\n",
    "\n",
    "draw_image(TF_RESULT_IMAGE, predictions, COMBO_RESULT_IMAGE, color=(0, 0, 255))\n",
    "\n",
    "show_results_interactively(tf_image=TF_RESULT_IMAGE,\n",
    "                           ie_image=IE_RESULT_IMAGE,\n",
    "                           combination_image=COMBO_RESULT_IMAGE,\n",
    "                           ie_fps=ie_avg_fps,\n",
    "                           tf_fps=tf_avg_fps)\n",
    "\n",
    "show_performance(PERFORMANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!accuracy_check -c ./workshop/data/configs/accuracy_checker_config.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ${INTEL_OPENVINO_DIR}/deployment_tools/model_optimizer/mo.py \\\n",
    "    --data_type FP16 \\\n",
    "    --output_dir=./workshop/data/public/ssd_mobilenet_v2_coco/FP16 \\\n",
    "    --reverse_input_channels \\\n",
    "    '--input_shape=[1,300,300,3]'\\\n",
    "    --model_name=ssd_mobilenet_v2_coco \\\n",
    "    --transformations_config=${INTEL_OPENVINO_DIR}/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json \\\n",
    "    --tensorflow_object_detection_api_pipeline_config=./workshop/data/public/ssd_mobilenet_v2_coco/ssd_mobilenet_v2_coco_2018_03_29/pipeline.config \\\n",
    "    --output=detection_classes,detection_scores,detection_boxes,num_detections \\\n",
    "    --input_model=./workshop/data/public/ssd_mobilenet_v2_coco/ssd_mobilenet_v2_coco_2018_03_29/frozen_inference_graph.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'GPU'\n",
    "ie_avg_fps, predictions = ie_inference(IE_MODEL_FP16_XML, IE_MODEL_FP16_BIN, device, '')\n",
    "\n",
    "draw_image(TF_RESULT_IMAGE, predictions, COMBO_RESULT_IMAGE, color=(0, 0, 255))\n",
    "\n",
    "show_results_interactively(tf_image=TF_RESULT_IMAGE,\n",
    "                           ie_image=IE_RESULT_IMAGE,\n",
    "                           combination_image=COMBO_RESULT_IMAGE,\n",
    "                           ie_fps=ie_avg_fps,\n",
    "                           tf_fps=tf_avg_fps)\n",
    "\n",
    "show_performance(PERFORMANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ${INTEL_OPENVINO_DIR}/deployment_tools/tools/post_training_optimization_toolkit/main.py -c ./workshop/data/configs/default/quantization_config.json \\\n",
    "                                                                                                 --output-dir ./workshop/data/public/ssd_mobilenet_v2_coco/INT8/default \\\n",
    "                                                                                                 --direct-dump \\\n",
    "                                                                                                 -e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'CPU'\n",
    "ie_avg_fps, predictions = ie_inference(IE_MODEL_DEFAULT_INT8_XML, IE_MODEL_DEFAULT_INT8_BIN, device, 'INT8 D')\n",
    "\n",
    "draw_image(TF_RESULT_IMAGE, predictions, COMBO_RESULT_IMAGE, color=(0, 0, 255))\n",
    "\n",
    "show_results_interactively(tf_image=TF_RESULT_IMAGE,\n",
    "                           ie_image=IE_RESULT_IMAGE,\n",
    "                           combination_image=COMBO_RESULT_IMAGE,\n",
    "                           ie_fps=ie_avg_fps,\n",
    "                           tf_fps=tf_avg_fps)\n",
    "\n",
    "show_performance(PERFORMANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!accuracy_check -c ./workshop/data/configs/default/accuracy_checker_config.yml | grep %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ${INTEL_OPENVINO_DIR}/deployment_tools/tools/post_training_optimization_toolkit/main.py \\\n",
    "    -c ./workshop/data/configs/accuracy_aware/quantization_config.json \\\n",
    "    --output-dir ./workshop/data/public/ssd_mobilenet_v2_coco/INT8/acuracy_aware \\\n",
    "    --direct-dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'CPU'\n",
    "ie_avg_fps, predictions = ie_inference(IE_MODEL_AA_INT8_XML, IE_MODEL_AA_INT8_BIN, device, 'INT8 AA')\n",
    "\n",
    "draw_image(TF_RESULT_IMAGE, predictions, COMBO_RESULT_IMAGE, color=(0, 0, 255))\n",
    "\n",
    "show_results_interactively(tf_image=TF_RESULT_IMAGE,\n",
    "                           ie_image=IE_RESULT_IMAGE,\n",
    "                           combination_image=COMBO_RESULT_IMAGE,\n",
    "                           ie_fps=ie_avg_fps,\n",
    "                           tf_fps=tf_avg_fps)\n",
    "\n",
    "show_performance(PERFORMANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!accuracy_check -c ./workshop/data/configs/accuracy_aware/accuracy_checker_config.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/samples/cpp/build/intel64/Release/benchmark_app -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/samples/cpp/build/intel64/Release/benchmark_app -m /home/atugarev/Developer/workshop/data/public/ssd_mobilenet_v2_coco/FP32/ssd_mobilenet_v2_coco.xml -d GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
